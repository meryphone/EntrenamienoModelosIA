shrinkage = c(0.01, 0.005),    # Tasa de aprendizaje más pequeña
n.minobsinnode = c(10, 15, 20)
)
# Entrenar modelo con GBM
set.seed(1234)
modelo_gbm <- train(
V16 ~ .,                              # Fórmula
data = credit.Datos.Train.Normalizados, # Datos normalizados
method = "gbm",                       # Método GBM
trControl = control,                  # Validación cruzada
tuneGrid = tuneGrid,                  # Rango de hiperparámetros
verbose = FALSE
)
# Evaluar el modelo
print(modelo_gbm)
cat("Mejores hiperparámetros encontrados:\n")
print(modelo_gbm$bestTune)
# Predicciones en el conjunto de prueba
predicciones <- predict(modelo_gbm, newdata = credit.Datos.Test.Normalizados)
matriz_confusion <- confusionMatrix(predicciones, credit.Datos.Test.Normalizados$V16)
print(matriz_confusion)
library(keras)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Paso 3: Compilar el modelo
modelo_keras3 %>% compile(
optimizer = optimizer_adam(learning_rate = 0.001),
loss = "binary_crossentropy",
metrics = c("accuracy")
)
library(tensorflow)
tensorflow::tf_config()
library(keras)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Paso 3: Compilar el modelo
tensorflow::tf$keras$models$Model$compile(
object = modelo_keras3,
optimizer = tensorflow::tf$keras$optimizers$Adam(learning_rate = 0.001),
loss = "binary_crossentropy",
metrics = list("accuracy")
)
library(keras)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Paso 3: Compilar el modelo
modelo_keras3$compile(
optimizer = tensorflow::tf$keras$optimizers$Adam(learning_rate = 0.001),
loss = "binary_crossentropy",
metrics = list("accuracy")
)
# Paso 4: Entrenar el modelo
history <- modelo_keras3 %>% fit(
x = x_train,
y = y_train,
epochs = 50,                 # Número de épocas
batch_size = 32,             # Tamaño del lote
validation_split = 0.2       # Proporción de validación
)
library(keras)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Paso 3: Compilar el modelo
modelo_keras3$compile(
optimizer = tensorflow::tf$keras$optimizers$Adam(learning_rate = 0.001),
loss = "binary_crossentropy",
metrics = list("accuracy")
)
# Paso 4: Entrenar el modelo
history <- modelo_keras3$fit(
x = x_train,
y = y_train,
epochs = 50,                 # Número de épocas
batch_size = 32,             # Tamaño del lote
validation_split = 0.2       # Proporción de datos para validación
)
reticulate::py_last_error()
library(keras)
library(caret)  # Para matriz de confusión
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Predictores de prueba
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1  # Objetivo de prueba
# Paso 2: Definir la arquitectura del modelo
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Paso 3: Compilar el modelo
modelo_keras3$compile(
optimizer = optimizer_adam(learning_rate = 0.001),  # Optimizador Adam
loss = "binary_crossentropy",                      # Pérdida para clasificación binaria
metrics = list("accuracy")                         # Métrica de evaluación
)
# Paso 4: Entrenar el modelo
history <- modelo_keras3$fit(
x = x_train,
y = y_train,
epochs = 50,                 # Número de épocas
batch_size = 32,             # Tamaño del lote
validation_split = 0.2       # Proporción de datos para validación
)
# Verificar dimensiones de los datos
dim(x_train)
dim(y_train)
# Confirmar que y_train es un vector numérico con valores 0 o 1
table(y_train)
library(keras)
library(caret)
# Paso 1: Preparar los datos
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")])
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
# Convertir y_train y y_test a matrices con dimensiones explícitas
y_train <- as.matrix(y_train)
y_test <- as.matrix(y_test)
# Verificar formas de los datos
cat("Forma de x_train:", dim(x_train), "\n")
cat("Forma de y_train:", dim(y_train), "\n")
# Paso 2: Definir el modelo
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Paso 3: Compilar el modelo
modelo_keras3$compile(
optimizer = optimizer_adam(learning_rate = 0.001),
loss = "binary_crossentropy",
metrics = list("accuracy")
)
# Paso 4: Entrenar el modelo
history <- modelo_keras3$fit(
x = x_train,
y = y_train,
epochs = 50,
batch_size = 32,
validation_split = 0.2
)
library(keras)
library(tensorflow)
library(caret)
# Paso 1: Preparar los datos
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")])
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")])
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
# Convertir a tipos compatibles con TensorFlow
x_train <- tensorflow::tf$cast(x_train, dtype = "float32")
y_train <- tensorflow::tf$cast(as.matrix(y_train), dtype = "int32")
x_test <- tensorflow::tf$cast(x_test, dtype = "float32")
y_test <- tensorflow::tf$cast(as.matrix(y_test), dtype = "int32")
# Paso 2: Definir el modelo
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Paso 3: Compilar el modelo
modelo_keras3$compile(
optimizer = optimizer_adam(learning_rate = 0.001),
loss = "binary_crossentropy",
metrics = list("accuracy")
)
# Paso 4: Entrenar el modelo
history <- modelo_keras3$fit(
x = x_train,
y = y_train,
epochs = 50,
batch_size = 32,
validation_split = 0.2
)
library(keras)
library(tensorflow)
# Preparar los datos
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")])
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")])
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
# Convertir a tipos compatibles con TensorFlow
x_train <- tensorflow::tf$cast(x_train, dtype = "float32")
x_test <- tensorflow::tf$cast(x_test, dtype = "float32")
y_train <- tensorflow::tf$cast(as.integer(y_train), dtype = "int32")
y_test <- tensorflow::tf$cast(as.integer(y_test), dtype = "int32")
# Definir el modelo
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Compilar el modelo
modelo_keras3$compile(
optimizer = optimizer_adam(learning_rate = 0.001),
loss = "binary_crossentropy",
metrics = list("accuracy")
)
# Dividir manualmente el conjunto de validación
set.seed(123)
validation_index <- sample(1:nrow(x_train), size = 0.2 * nrow(x_train))
x_val <- x_train[validation_index, ]
library(keras)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
# Convertir a matrices R estándar
x_train_r <- as.matrix(x_train)
y_train_r <- as.vector(y_train)
# Dividir el conjunto de validación manualmente
set.seed(123)
validation_index <- sample(1:nrow(x_train_r), size = 0.2 * nrow(x_train_r))
x_val <- x_train_r[validation_index, ]
y_val <- y_train_r[validation_index]
x_train_r <- x_train_r[-validation_index, ]
y_train_r <- y_train_r[-validation_index]
# Confirmar las dimensiones después de dividir
cat("x_train_r:", dim(x_train_r), "\n")
cat("y_train_r:", length(y_train_r), "\n")
cat("x_val:", dim(x_val), "\n")
cat("y_val:", length(y_val), "\n")
# Convertir los conjuntos de entrenamiento y validación a tensores
x_train_tf <- tensorflow::tf$convert_to_tensor(x_train_r, dtype = "float32")
y_train_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_train_r), dtype = "int32")
x_val_tf <- tensorflow::tf$convert_to_tensor(x_val, dtype = "float32")
y_val_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_val), dtype = "int32")
# Paso 2: Construir el modelo
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Paso 3: Compilar el modelo
modelo_keras3$compile(
optimizer = tensorflow::tf$keras$optimizers$Adam(learning_rate = 0.001),
loss = "binary_crossentropy",
metrics = list("accuracy")
)
# Paso 4: Entrenar el modelo
history <- modelo_keras3$fit(
x = x_train_tf,
y = y_train_tf,
epochs = 50,
batch_size = 32,
validation_data = list(x_val_tf, y_val_tf)
)
library(keras)
library(tensorflow)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
# Dividir el conjunto de validación manualmente
set.seed(123)
validation_index <- sample(1:nrow(x_train), size = as.integer(0.2 * nrow(x_train)))
x_val <- x_train[validation_index, ]
y_val <- y_train[validation_index]
x_train <- x_train[-validation_index, ]
y_train <- y_train[-validation_index]
# Confirmar las dimensiones después de dividir
cat("x_train:", dim(x_train), "\n")
cat("y_train:", length(y_train), "\n")
cat("x_val:", dim(x_val), "\n")
cat("y_val:", length(y_val), "\n")
# Convertir los conjuntos a tensores asegurando el tipo correcto
x_train_tf <- tensorflow::tf$convert_to_tensor(x_train, dtype = "float32")
y_train_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_train), dtype = "int32")
x_val_tf <- tensorflow::tf$convert_to_tensor(x_val, dtype = "float32")
y_val_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_val), dtype = "int32")
x_test_tf <- tensorflow::tf$convert_to_tensor(x_test, dtype = "float32")
y_test_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_test), dtype = "int32")
# Paso 2: Construir el modelo
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Paso 3: Compilar el modelo
modelo_keras3$compile(
optimizer = tensorflow::tf$keras$optimizers$Adam(learning_rate = 0.001),
loss = "binary_crossentropy",
metrics = list("accuracy")
)
# Paso 4: Entrenar el modelo
history <- modelo_keras3$fit(
x = x_train_tf,
y = y_train_tf,
epochs = 50,
batch_size = 32,
validation_data = list(x_val_tf, y_val_tf)
)
library(keras)
library(tensorflow)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
# Dividir el conjunto de validación manualmente
set.seed(123)
validation_index <- sample(seq_len(nrow(x_train)), size = floor(0.2 * nrow(x_train)))
x_val <- x_train[validation_index, ]
y_val <- y_train[validation_index]
x_train <- x_train[-validation_index, ]
y_train <- y_train[-validation_index]
# Verificar las dimensiones
cat("x_train dimensiones:", dim(x_train), "\n")
cat("y_train dimensiones:", length(y_train), "\n")
cat("x_val dimensiones:", dim(x_val), "\n")
cat("y_val dimensiones:", length(y_val), "\n")
# Convertir a tensores y asegurar los tipos
x_train_tf <- tensorflow::tf$convert_to_tensor(x_train, dtype = "float32")
y_train_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_train), dtype = "int32")
x_val_tf <- tensorflow::tf$convert_to_tensor(x_val, dtype = "float32")
y_val_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_val), dtype = "int32")
x_test_tf <- tensorflow::tf$convert_to_tensor(x_test, dtype = "float32")
y_test_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_test), dtype = "int32")
# Confirmar tipos y formas de los tensores
cat("x_train_tf dtype:", tensorflow::tf$dtypes$as_dtype(x_train_tf$dtype)$name, "shape:", x_train_tf$shape, "\n")
library(keras)
library(tensorflow)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
# Dividir el conjunto de validación manualmente
set.seed(123)
validation_index <- sample(seq_len(nrow(x_train)), size = floor(0.2 * nrow(x_train)))
x_val <- x_train[validation_index, ]
y_val <- y_train[validation_index]
x_train <- x_train[-validation_index, ]
y_train <- y_train[-validation_index]
# Verificar las dimensiones
# Confirmar tipos y formas de los tensores
cat("x_train_tf dtype:", tensorflow::tf$dtypes$as_dtype(x_train_tf$dtype)$name, "\n")
cat("x_train_tf shape:", as.character(x_train_tf$shape), "\n")
cat("y_train_tf dtype:", tensorflow::tf$dtypes$as_dtype(y_train_tf$dtype)$name, "\n")
cat("y_train_tf shape:", as.character(y_train_tf$shape), "\n")
cat("x_val_tf dtype:", tensorflow::tf$dtypes$as_dtype(x_val_tf$dtype)$name, "\n")
cat("x_val_tf shape:", as.character(x_val_tf$shape), "\n")
cat("y_val_tf dtype:", tensorflow::tf$dtypes$as_dtype(y_val_tf$dtype)$name, "\n")
cat("y_val_tf shape:", as.character(y_val_tf$shape), "\n")
# Convertir a tensores y asegurar los tipos
x_train_tf <- tensorflow::tf$convert_to_tensor(x_train, dtype = "float32")
y_train_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_train), dtype = "int32")
x_val_tf <- tensorflow::tf$convert_to_tensor(x_val, dtype = "float32")
y_val_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_val), dtype = "int32")
x_test_tf <- tensorflow::tf$convert_to_tensor(x_test, dtype = "float32")
y_test_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_test), dtype = "int32")
# Confirmar tipos y formas de los tensores
cat("x_train_tf dtype:", tensorflow::tf$dtypes$as_dtype(x_train_tf$dtype)$name, "shape:", x_train_tf$shape, "\n")
library(keras)
library(tensorflow)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
# Dividir el conjunto de validación manualmente
set.seed(123)
validation_index <- sample(seq_len(nrow(x_train)), size = floor(0.2 * nrow(x_train)))
x_val <- x_train[validation_index, ]
y_val <- y_train[validation_index]
x_train <- x_train[-validation_index, ]
y_train <- y_train[-validation_index]
# Verificar las dimensiones
# Convertir a tensores y asegurar los tipos
x_train_tf <- tensorflow::tf$convert_to_tensor(x_train, dtype = "float32")
y_train_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_train), dtype = "int32")
x_val_tf <- tensorflow::tf$convert_to_tensor(x_val, dtype = "float32")
y_val_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_val), dtype = "int32")
x_test_tf <- tensorflow::tf$convert_to_tensor(x_test, dtype = "float32")
y_test_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_test), dtype = "int32")
# Confirmar tipos y formas de los tensores
cat("x_train_tf dtype:", tensorflow::tf$dtypes$as_dtype(x_train_tf$dtype)$name, "shape:", x_train_tf$shape, "\n")
library(keras)
library(tensorflow)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
# Dividir el conjunto de validación manualmente
set.seed(123)
validation_index <- sample(seq_len(nrow(x_train)), size = floor(0.2 * nrow(x_train)))
x_val <- x_train[validation_index, ]
y_val <- y_train[validation_index]
x_train <- x_train[-validation_index, ]
y_train <- y_train[-validation_index]
# Verificar las dimensiones
# Convertir a tensores y asegurar los tipos
x_train_tf <- tensorflow::tf$convert_to_tensor(x_train, dtype = "float32")
y_train_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_train), dtype = "int32")
x_val_tf <- tensorflow::tf$convert_to_tensor(x_val, dtype = "float32")
y_val_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_val), dtype = "int32")
x_test_tf <- tensorflow::tf$convert_to_tensor(x_test, dtype = "float32")
y_test_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_test), dtype = "int32")
# Confirmar tipos y formas de los tensores
cat("x_train_tf dtype:", tensorflow::tf$dtypes$as_dtype(x_train_tf$dtype)$name, "shape:", x_train_tf$shape, "\n")
library(keras)
library(tensorflow)
# Paso 1: Preparar los datos
# Separar predictores y variable objetivo
x_train <- as.matrix(credit.Datos.Train.Normalizados[, -which(names(credit.Datos.Train.Normalizados) == "V16")]) # Predictores
y_train <- as.numeric(credit.Datos.Train.Normalizados$V16) - 1 # Variable objetivo (0/1)
x_test <- as.matrix(credit.Datos.Test.Normalizados[, -which(names(credit.Datos.Test.Normalizados) == "V16")]) # Test
y_test <- as.numeric(credit.Datos.Test.Normalizados$V16) - 1
# Dividir el conjunto de validación manualmente
set.seed(123)
validation_index <- sample(seq_len(nrow(x_train)), size = floor(0.2 * nrow(x_train)))
x_val <- x_train[validation_index, ]
y_val <- y_train[validation_index]
x_train <- x_train[-validation_index, ]
y_train <- y_train[-validation_index]
# Verificar las dimensiones
# Convertir a tensores y asegurar los tipos
x_train_tf <- tensorflow::tf$convert_to_tensor(x_train, dtype = "float32")
y_train_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_train), dtype = "int32")
x_val_tf <- tensorflow::tf$convert_to_tensor(x_val, dtype = "float32")
y_val_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_val), dtype = "int32")
x_test_tf <- tensorflow::tf$convert_to_tensor(x_test, dtype = "float32")
y_test_tf <- tensorflow::tf$convert_to_tensor(as.integer(y_test), dtype = "int32")
# Paso 2: Construir el modelo
input <- layer_input(shape = ncol(x_train), dtype = "float32", name = "features")
hidden <- input %>%
layer_dense(units = 64, activation = "relu") %>%
layer_dense(units = 32, activation = "relu")
output <- hidden %>%
layer_dense(units = 1, activation = "sigmoid")
modelo_keras3 <- keras_model(inputs = input, outputs = output)
# Paso 3: Compilar el modelo
modelo_keras3$compile(
optimizer = tensorflow::tf$keras$optimizers$Adam(learning_rate = 0.001),
loss = "binary_crossentropy",
metrics = list("accuracy")
)
# Paso 4: Entrenar el modelo
history <- modelo_keras3$fit(
x = x_train_tf,
y = y_train_tf,
epochs = 50,
batch_size = 32,
validation_data = list(x_val_tf, y_val_tf)
)
