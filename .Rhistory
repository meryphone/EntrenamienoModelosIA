ggplot(credit, aes(x = V14)) +
geom_histogram(binwidth = 14, fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histograma de credit$V14", x = "Valores de V14", y = "Frecuencia") +
theme_minimal()
ggplot(credit, aes(x = V15)) +
geom_histogram( fill = "blue", color = "black", alpha = 0.7) +
labs(title = "Histograma de V15", x = "Valores de V15", y = "Frecuencia") +
theme_minimal()
levels(credit$V16)
summary(credit$V2)
myhist = ggplot(data=na.omit(credit),aes(V2)) +
geom_histogram(col="orange",fill="orange",alpha=0.2) +
labs(title="Histograma para V2", y="Count")
myhist = myhist + geom_vline(xintercept = mean(credit$V2),
col="blue",linetype="dashed")
myhist = myhist + geom_vline(xintercept = median(credit$V2),
col="red",linetype="dashed")
myhist
myplot = ggplot(data=na.omit(credit),aes(sample=V2)) +
ggtitle("QQ plot para V2") +
geom_qq() +
stat_qq_line() +
xlab("Distribución teórica") + ylab("Distribución muestral")
myplot
summary(credit$V3)
myhist=ggplot(data=credit, aes(x = V3)) +
geom_histogram(col = "orange", fill = "orange", alpha = 0.2,
breaks = seq(0, 30, by = 1)) +
labs(title = "Histograma para el análisis de la variable V3", y = "Count")
# Marca el valor de la media con una línea azul vertical
myhist <- myhist + geom_vline(xintercept = mean(credit$V3),
col = "blue", linetype = "dashed")
# Marca el valor de la mediana con una línea roja vertical
myhist <- myhist + geom_vline(xintercept = median(credit$V3),
col = "red", linetype = "dashed")
myhist
ggplot(credit, aes(sample = V3)) +
stat_qq() +
stat_qq_line(color = "blue", linetype = "dashed") +
labs(title = "Diagrama Q-Q de V3", x = "Cuantiles Teóricos", y = "Cuantiles Muestrales")
summary(credit$V8)
myhist = ggplot(data=credit, aes(x = V8)) +
geom_histogram(col="orange", fill="orange", alpha=0.2,
breaks=seq(0, 30, by=1)) +
labs(title="Histograma para el análisis de la variable V8", y="Count")
# Marca el valor de la media con una línea azul vertical
myhist = myhist + geom_vline(xintercept = mean(credit$V8),
col="blue", linetype="dashed")
# Marca el valor de la mediana con una línea roja vertical
myhist = myhist + geom_vline(xintercept = median(credit$V8),
col="red", linetype="dashed")
# Mostrar el histograma
myhist
ggplot(data = credit, aes(sample = V8)) +
ggtitle("QQ plot para variable V8") +
stat_qq() +
stat_qq_line() +
xlab("Distribución teórica") +
ylab("Distribución muestral")
# Matriz de dispersión para analizar la relación entre V2, V3, V8 y V16
ggpairs(na.omit(credit), columns = c("V2", "V3", "V8","V14","V15", "V16"),aes(color = V16, alpha = 0.6), title = "Análisis Multivariable de V2 V3 V8 V4 Y V15")
Q1=quantile(na.omit(credit$V2),0.25)
Q3=quantile(na.omit(credit$V2),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosv2=na.omit(credit$V2)[na.omit(credit$V2)<limiteInferior | na.omit(credit$V2)>limiteSuperior]
percAtipicos=100*length(atipicosv2)/length((na.omit(credit$V2)))
print(paste("El porcentaje de datos atípicos para V2 es = ",percAtipicos))
Q1=quantile(na.omit(credit$V3),0.25)
Q3=quantile(na.omit(credit$V3),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosv3=na.omit(credit$V3)[na.omit(credit$V3)<limiteInferior | na.omit(credit$V3)>limiteSuperior]
percAtipicos=100*length(atipicosv3)/length((na.omit(credit$V3)))
print(paste("El porcentaje de datos atípicos para V3 es = ",percAtipicos))
Q1=quantile(na.omit(credit$V14),0.25)
Q3=quantile(na.omit(credit$V14),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosv14=na.omit(credit$V14)[na.omit(credit$V14)<limiteInferior | na.omit(credit$V14)>limiteSuperior]
percAtipicos=100*length(atipicosv14)/length((na.omit(credit$V14)))
print(paste("El porcentaje de datos atípicos para V14 es = ",percAtipicos))
Q1=quantile(na.omit(credit$V8),0.25)
Q3=quantile(na.omit(credit$V8),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosv8=na.omit(credit$V8)[na.omit(credit$V8)<limiteInferior | na.omit(credit$V8)>limiteSuperior]
percAtipicos=100*length(atipicosv8)/length((na.omit(credit$V8)))
print(paste("El porcentaje de datos atípicos es = ",percAtipicos))
ggplot(credit, aes(x = V8)) +
geom_histogram(bins = 30, fill = "orange", color = "black", alpha = 0.7) +
labs(title = "Histograma de V8 original", x = "V8 (original)", y = "Frecuencia")
ggplot(credit, aes(y = V8)) +
geom_boxplot(fill = "skyblue", color = "darkblue", outlier.color = "red", outlier.shape = 16) +
labs(title = "Boxplot de V8", y = "V8", x = "") +
theme_minimal()
Q1=quantile(na.omit(credit$V11),0.25)
Q3=quantile(na.omit(credit$V11),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosV11=na.omit(credit$V11)[na.omit(credit$V11)<limiteInferior | na.omit(credit$V11)>limiteSuperior]
percAtipicos=100*length(atipicosV11)/length((na.omit(credit$V11)))
print(paste("El porcentaje de datos atípicos es = ",percAtipicos))
ggplot(credit, aes(x = V11)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
labs(title = "Histograma de la Variable V11", x = "V11(original)", y = "Frecuencia") +
theme_minimal()
ggplot(credit, aes(y = V11)) +
geom_boxplot(fill = "skyblue", color = "darkblue", outlier.color = "red", outlier.shape = 16) +
labs(title = "Boxplot de V11", y = "V11", x = "") +
theme_minimal()
Q1=quantile(na.omit(credit$V15),0.25)
Q3=quantile(na.omit(credit$V15),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosV15=na.omit(credit$V15)[na.omit(credit$V15)<limiteInferior | na.omit(credit$V15)>limiteSuperior]
percAtipicos=100*length(atipicosV15)/length((na.omit(credit$V15)))
print(paste("El porcentaje de datos atípicos es = ",percAtipicos))
ggplot(credit, aes(x = V15)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
labs(title = "Histograma de la Variable V15", x = "V15", y = "Frecuencia") +
theme_minimal()
ggplot(credit, aes(y = V15)) +
geom_boxplot(fill = "skyblue", color = "darkblue", outlier.color = "red", outlier.shape = 16) +
labs(title = "Boxplot de V15", y = "V15", x = "") +
theme_minimal()
credit.trainIdx<-readRDS("credit.trainIdx")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Train[!complete.cases(credit.Datos.Train),])
# Visualización rápida de la matriz de correlación en forma de símbolos
symnum(cor(credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)], use = "complete.obs"))
preproc <- preProcess(credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)], method = "medianImpute")
credit_num_imputed <- predict(preproc, credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)])
# Verificar que no hay valores nulos en el nuevo dataframe
sum(is.na(credit_num_imputed))
credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)] <- credit_num_imputed
imputar_moda <- function(x) {
if (is.factor(x) || is.character(x)) {
# Calcular la moda (valor más frecuente)
moda <- names(sort(table(x), decreasing = TRUE))[1]
# Reemplazar los NA con la moda
x[is.na(x)] <- moda
}
return(x)
}
credit.Datos.Train <- data.frame(lapply(credit.Datos.Train, imputar_moda))
#Comprobar que todo ha ido bien
nrow(credit.Datos.Train[!complete.cases(credit.Datos.Train),])
credit.Datos.Train[!complete.cases(credit.Datos.Train),]
nearZeroVar(credit.Datos.Train)
symnum(cor(credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)]))
credit.Datos.Train.Normalizados=credit.Datos.Train
# Aplicar preProcess para centrar en la mediana y escalar por el RIC
preproc <- preProcess(credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")], method = c("center", "scale"),
center = apply(credit.Datos.Train[, c("V8", "V11", "V15")], 2, median),
scale = apply(credit.Datos.Train[, c("V8", "V11", "V15")], 2, IQR))
credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")] <- predict(preproc, credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")])
# Verificar los resultados
head(credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")])
credit.Datos.Train.Normalizados$V2=log1p(credit.Datos.Train.Normalizados$V2)
credit.Datos.Train.Normalizados$V3=log1p(credit.Datos.Train.Normalizados$V3)
credit.Datos.Train.Normalizados$V14=log1p(credit.Datos.Train.Normalizados$V14)
min_max_normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
credit.Datos.Train.Normalizados$V2=min_max_normalize(credit.Datos.Train.Normalizados$V2)
credit.Datos.Train.Normalizados$V3=min_max_normalize(credit.Datos.Train.Normalizados$V3)
credit.Datos.Train.Normalizados$V14=min_max_normalize(credit.Datos.Train.Normalizados$V14)
summary(credit.Datos.Train.Normalizados[, c("V2", "V3", "V14")])
credit.Datos.Test.Normalizados=credit.Datos.Test
credit.Datos.Test.Normalizados$V2=log1p(credit.Datos.Test.Normalizados$V2)
credit.Datos.Test.Normalizados$V3=log1p(credit.Datos.Test.Normalizados$V3)
credit.Datos.Test.Normalizados$V14=log1p(credit.Datos.Test.Normalizados$V14)
credit.Datos.Test.Normalizados$V2=min_max_normalize(credit.Datos.Test.Normalizados$V2)
credit.Datos.Test.Normalizados$V3=min_max_normalize(credit.Datos.Test.Normalizados$V3)
credit.Datos.Test.Normalizados$V14=min_max_normalize(credit.Datos.Test.Normalizados$V14)
#Utilizamos la variable 'prepoc' creada anteriormente con los datos de TRAIN para evitar peaking
credit.Datos.Test.Normalizados[, c("V8", "V11", "V15")] <- predict(preproc, credit.Datos.Test.Normalizados[, c("V8", "V11", "V15")])
predictors <- credit.Datos.Train[, -which(names(credit.Datos.Train) == "V16")]
target <- credit.Datos.Train$V16
rf_model <- randomForest(x = predictors, y = target, importance = TRUE)
importance_rf <- importance(rf_model)
varImpPlot(rf_model)
credit.Datos.Train.Rf=credit.Datos.Train
credit.Datos.Train.Rf$V2=log1p(credit.Datos.Train.Rf$V2)
credit.Datos.Train.Rf$V3=log1p(credit.Datos.Train.Rf$V3)
credit.Datos.Train.Rf$V8=log1p(credit.Datos.Train.Rf$V8)
credit.Datos.Train.Rf$V11=log1p(credit.Datos.Train.Rf$V11)
credit.Datos.Train.Rf$V14=log1p(credit.Datos.Train.Rf$V14)
credit.Datos.Train.Rf$V15=log1p(credit.Datos.Train.Rf$V15)
ggplot(credit.Datos.Train, aes(x = V2)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
labs(title = "Histograma de V2", x = "V2", y = "Frecuencia") +
theme_minimal()
credit.Datos.Test.Rf=credit.Datos.Test
credit.Datos.Test.Rf$V2=log1p(credit.Datos.Test.Rf$V2)
credit.Datos.Test.Rf$V3=log1p(credit.Datos.Test.Rf$V3)
credit.Datos.Test.Rf$V8=log1p(credit.Datos.Test.Rf$V8)
credit.Datos.Test.Rf$V11=log1p(credit.Datos.Test.Rf$V11)
credit.Datos.Test.Rf$V14=log1p(credit.Datos.Test.Rf$V14)
credit.Datos.Test.Rf$V15=log1p(credit.Datos.Test.Rf$V15)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
print(modelo_rf_cv)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
modelo_nnet <- train(
V16 ~ .,                           # Reemplaza `Target` con tu variable objetivo
data = credit.Datos.Train.Normalizados,
method = "nnet",
trControl = control,
tuneLength = 5,
trace = FALSE
)
print(modelo_nnet)
predicciones <- predict(modelo_nnet, credit.Datos.Test.Normalizados) # Reemplaza con tu conjunto de test
confusionMatrix(predicciones, credit.Datos.Test$V16)
modelLookup(("nnet"))
# Definir un grid de hiperparámetros
grid <- expand.grid(
size = c(1, 3, 5, 7),              # Nodos en la capa oculta
decay = c(1e-05, 1e-04, 1e-03, 1e-02) # Regularización
)
# Crear un data frame para almacenar resultados
resultados <- data.frame(size = numeric(),
decay = numeric(),
precision_test = numeric())
# Loop para probar cada combinación del grid
for (i in 1:nrow(grid)) {
size <- grid$size[i]
decay <- grid$decay[i]
# Entrenar el modelo con los hiperparámetros actuales
set.seed(123)
modelo <- train(
V16 ~ .,
data = credit.Datos.Train,
method = "nnet",
trControl = trainControl(method = "none"), # Sin validación cruzada, entrenamos directamente
tuneGrid = expand.grid(size = size, decay = decay),
trace = FALSE
)
# Predicciones en el conjunto de test
predicciones <- predict(modelo, newdata = credit.Datos.Test)
# Calcular precisión sobre el conjunto de test usando confusionMatrix
conf_matrix <- confusionMatrix(predicciones, credit.Datos.Test$V16)
precision_test <- conf_matrix$overall["Accuracy"]  # Extraer la precisión
# Almacenar resultados
resultados <- rbind(resultados, data.frame(size = size, decay = decay, precision_test = precision_test))
}
# Ordenar resultados por precisión descendente
resultados <- resultados[order(-resultados$precision_test), ]
print(resultados)
mejores_parametros <- resultados[1, ] # Mejor combinación según el test
size_mejor <- mejores_parametros$size
decay_mejor <- mejores_parametros$decay
set.seed(123)
modelo_final <- train(
V16 ~ .,
data = credit.Datos.Train,
method = "nnet",
trControl = trainControl(method = "none"),
tuneGrid = expand.grid(size = size_mejor, decay = decay_mejor),
trace = FALSE
)
# Evaluar el modelo final en el conjunto de test
predicciones_final <- predict(modelo_final, newdata = credit.Datos.Test)
confusionMatrix(predicciones_final, credit.Datos.Test$V16)
set.seed(1234)
knn_model <- train(
V16 ~ .,
data = credit.Datos.Train.Normalizados,
method = "knn",
trControl = control,
tuneLength = 10
)
print(knn_model)
# Realizar predicciones en el conjunto de prueba
knn_predictions <- predict(knn_model, newdata = credit.Datos.Test.Normalizados)
# Calcular la matriz de confusión
confusionMatrix(knn_predictions, credit.Datos.Test.Normalizados$V16)
set.seed(1234)
suppressWarnings({
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)})
print(gbm_model)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_model, newdata = credit.Datos.Test.Normalizados)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.Normalizados$V16)
# Calcular la importancia de las variables directamente desde gbm
importancia_directa <- summary(gbm_model$finalModel)  # Si entrenaste con caret
credit.Datos.Train.gbm = credit.Datos.Train
credit.Datos.Test.gbm = credit.Datos.Test
# Eliminar las columnas específicas por nombre
credit.Datos.Train.gbm <- credit.Datos.Train.gbm[, !colnames(credit.Datos.Train.gbm) %in% c("V4", "V6", "V13")]
credit.Datos.Test.gbm <- credit.Datos.Test.gbm[, !colnames(credit.Datos.Test.gbm) %in% c("V4", "V6", "V13")]
set.seed(1234)
suppressWarnings({
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.gbm,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)})
print(gbm_model)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_model, newdata = credit.Datos.Test.gbm)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.gbm$V16)
# Aplicar la transformación Box-Cox a las variables numéricas
preprocess <- preProcess(credit.Datos.Train.gbm, method = "range")
# Transformar los datos de entrenamiento
credit.Datos.Train.gbm.normalizado <- predict(preprocess, credit.Datos.Train.gbm)
credit.Datos.Test.gbm.normalizado <- predict(preprocess, credit.Datos.Test.gbm)
# Verificar el resultado
summary(credit.Datos.Test.gbm.normalizado)
set.seed(1234)
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.gbm.normalizado,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_model, newdata = credit.Datos.Test.gbm.normalizado)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.gbm.normalizado$V16)
print(gbm_model)
# Definir el grid de hiperparámetros
tune_grid <- expand.grid(
n.trees = c(50, 100, 200),             # Número de árboles
interaction.depth = c(2, 3, 4, 5),     # Profundidad de los árboles
shrinkage = c(0.01, 0.05, 0.1),        # Tasa de aprendizaje
n.minobsinnode = c(5, 10, 15)          # Observaciones mínimas por nodo
)
# Control de validación cruzada
control <- trainControl(method = "cv", number = 5)  # Validación cruzada de 5 pliegues
# Entrenar el modelo GBM
set.seed(1234)
gbm_tuned <- train(
V16 ~ .,                              # Fórmula del modelo
data = credit.Datos.Train.gbm.normalizado, # Datos de entrenamiento
method = "gbm",                       # Modelo GBM
trControl = control,                  # Control de validación cruzada
tuneGrid = tune_grid,                 # Grid de hiperparámetros
verbose = FALSE                       # Sin salida de consola para GBM
)
# Ver los resultados
print(gbm_tuned)
plot(gbm_tuned)
# Mejor configuración encontrada
print(gbm_tuned$bestTune)
# Definir el grid de hiperparámetros
tune_grid <- expand.grid(
n.trees = c(50, 100, 200),             # Número de árboles
interaction.depth = c(2, 3, 4, 5),     # Profundidad de los árboles
shrinkage = c(0.01, 0.05, 0.1),        # Tasa de aprendizaje
n.minobsinnode = c(5, 10, 15)          # Observaciones mínimas por nodo
)
# Control de validación cruzada
control <- trainControl(method = "cv", number = 5)  # Validación cruzada de 5 pliegues
# Entrenar el modelo GBM
set.seed(1234)
gbm_tuned <- train(
V16 ~ .,                              # Fórmula del modelo
data = credit.Datos.Train.gbm.normalizado, # Datos de entrenamiento
method = "gbm",                       # Modelo GBM
trControl = control,                  # Control de validación cruzada
tuneGrid = tune_grid,                 # Grid de hiperparámetros
verbose = FALSE                       # Sin salida de consola para GBM
)
# Ver los resultados
print(gbm_tuned)
plot(gbm_tuned)
# Mejor configuración encontrada
print(gbm_tuned$bestTune)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_tuned, newdata = credit.Datos.Test.gbm.normalizado)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.gbm.normalizado$V16)
library(caret)
# Grid ajustado alrededor de los valores óptimos
tune_grid <- expand.grid(
n.trees = c(90, 100, 110),            # Ajuste en el número de árboles
interaction.depth = c(2, 3, 4),       # Ajuste leve en profundidad
shrinkage = c(0.08, 0.1, 0.12),       # Tasa de aprendizaje cercana a 0.1
n.minobsinnode = c(8, 10, 12)         # Observaciones mínimas por nodo
)
# Validación cruzada más robusta
control <- trainControl(method = "cv", number = 10)  # Validación cruzada de 10 pliegues
# Entrenar el modelo GBM
set.seed(1234)
gbm_tuned <- train(
V16 ~ .,
data = credit.Datos.Train.gbm.normalizado,
method = "gbm",
trControl = control,
tuneGrid = tune_grid,
verbose = FALSE
)
# Resultados
print(gbm_tuned)
plot(gbm_tuned)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_tuned, newdata = credit.Datos.Test.gbm.normalizado)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.gbm.normalizado$V16)
library(caret)
# Grid ajustado para fine-tuning
tune_grid <- expand.grid(
n.trees = c(90, 100, 110),            # Valores cercanos a 100
interaction.depth = c(3, 4, 5),       # Ajuste leve en profundidad
shrinkage = c(0.08, 0.1, 0.12),       # Tasa de aprendizaje cercana a 0.1
n.minobsinnode = c(7, 8, 9)           # Valores cercanos a 8
)
# Control de validación cruzada
control <- trainControl(method = "cv", number = 10)  # Validación cruzada más robusta
# Entrenar el modelo GBM
set.seed(1234)
gbm_tuned <- train(
V16 ~ .,
data = credit.Datos.Train.gbm.normalizado,
method = "gbm",
trControl = control,
tuneGrid = tune_grid,
verbose = FALSE
)
# Resultados
print(gbm_tuned)
plot(gbm_tuned)
# Mejor configuración encontrada
print(gbm_tuned$bestTune)
# Predicciones en el conjunto de test
predicciones <- predict(gbm_tuned, newdata = credit.Datos.Test.gbm.normalizado)
conf_matrix <- confusionMatrix(predicciones, credit.Datos.Test.gbm.normalizado$V16)
print(conf_matrix)
# Grid ajustado alrededor de los valores óptimos
tune_grid <- expand.grid(
n.trees = c(90, 100, 110),            # Ajuste en el número de árboles
interaction.depth = c(2, 3, 4),       # Ajuste leve en profundidad
shrinkage = c(0.08, 0.1, 0.12),       # Tasa de aprendizaje cercana a 0.1
n.minobsinnode = c(8, 10, 12)         # Observaciones mínimas por nodo
)
# Validación cruzada más robusta
control <- trainControl(method = "cv", number = 10)  # Validación cruzada de 10 pliegues
# Entrenar el modelo GBM
set.seed(1234)
gbm_tuned <- train(
V16 ~ .,
data = credit.Datos.Train.gbm.normalizado,
method = "gbm",
trControl = control,
tuneGrid = tune_grid,
verbose = FALSE
)
# Resultados
print(gbm_tuned)
plot(gbm_tuned)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_tuned, newdata = credit.Datos.Test.gbm.normalizado)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.gbm.normalizado$V16)
# Grid ajustado alrededor de los valores óptimos
tune_grid <- expand.grid(
n.trees = c(90, 100, 110),            # Ajuste en el número de árboles
interaction.depth = c(2, 3, 4),       # Ajuste leve en profundidad
shrinkage = c(0.08, 0.1, 0.12),       # Tasa de aprendizaje cercana a 0.1
n.minobsinnode = c(8, 10, 12)         # Observaciones mínimas por nodo
)
# Validación cruzada más robusta
control <- trainControl(method = "cv", number = 10)  # Validación cruzada de 10 pliegues
# Entrenar el modelo GBM
set.seed(1234)
gbm_tuned <- train(
V16 ~ .,
data = credit.Datos.Train.gbm.normalizado,
method = "gbm",
trControl = control,
tuneGrid = tune_grid,
verbose = FALSE
)
plot(gbm_tuned)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_tuned, newdata = credit.Datos.Test.gbm.normalizado)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.gbm.normalizado$V16)
