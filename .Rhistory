stat_qq_line(color = "blue", linetype = "dashed") +
labs(title = "Diagrama Q-Q de V3", x = "Cuantiles Teóricos", y = "Cuantiles Muestrales")
summary(credit$V8)
myhist = ggplot(data=credit, aes(x = V8)) +
geom_histogram(col="orange", fill="orange", alpha=0.2,
breaks=seq(0, 30, by=1)) +
labs(title="Histograma para el análisis de la variable V8", y="Count")
# Marca el valor de la media con una línea azul vertical
myhist = myhist + geom_vline(xintercept = mean(credit$V8),
col="blue", linetype="dashed")
# Marca el valor de la mediana con una línea roja vertical
myhist = myhist + geom_vline(xintercept = median(credit$V8),
col="red", linetype="dashed")
# Mostrar el histograma
myhist
ggplot(data = credit, aes(sample = V8)) +
ggtitle("QQ plot para variable V8") +
stat_qq() +
stat_qq_line() +
xlab("Distribución teórica") +
ylab("Distribución muestral")
# Matriz de dispersión para analizar la relación entre V2, V3, V8 y V16
ggpairs(na.omit(credit), columns = c("V2", "V3", "V8","V14","V15", "V16"),aes(color = V16, alpha = 0.6), title = "Análisis Multivariable de V2 V3 V8 V4 Y V15")
Q1=quantile(na.omit(credit$V2),0.25)
Q3=quantile(na.omit(credit$V2),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosv2=na.omit(credit$V2)[na.omit(credit$V2)<limiteInferior | na.omit(credit$V2)>limiteSuperior]
percAtipicos=100*length(atipicosv2)/length((na.omit(credit$V2)))
print(paste("El porcentaje de datos atípicos para V2 es = ",percAtipicos))
Q1=quantile(na.omit(credit$V3),0.25)
Q3=quantile(na.omit(credit$V3),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosv3=na.omit(credit$V3)[na.omit(credit$V3)<limiteInferior | na.omit(credit$V3)>limiteSuperior]
percAtipicos=100*length(atipicosv3)/length((na.omit(credit$V3)))
print(paste("El porcentaje de datos atípicos para V3 es = ",percAtipicos))
Q1=quantile(na.omit(credit$V14),0.25)
Q3=quantile(na.omit(credit$V14),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosv14=na.omit(credit$V14)[na.omit(credit$V14)<limiteInferior | na.omit(credit$V14)>limiteSuperior]
percAtipicos=100*length(atipicosv14)/length((na.omit(credit$V14)))
print(paste("El porcentaje de datos atípicos para V14 es = ",percAtipicos))
Q1=quantile(na.omit(credit$V8),0.25)
Q3=quantile(na.omit(credit$V8),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosv8=na.omit(credit$V8)[na.omit(credit$V8)<limiteInferior | na.omit(credit$V8)>limiteSuperior]
percAtipicos=100*length(atipicosv8)/length((na.omit(credit$V8)))
print(paste("El porcentaje de datos atípicos es = ",percAtipicos))
ggplot(credit, aes(x = V8)) +
geom_histogram(bins = 30, fill = "orange", color = "black", alpha = 0.7) +
labs(title = "Histograma de V8 original", x = "V8 (original)", y = "Frecuencia")
ggplot(credit, aes(y = V8)) +
geom_boxplot(fill = "skyblue", color = "darkblue", outlier.color = "red", outlier.shape = 16) +
labs(title = "Boxplot de V8", y = "V8", x = "") +
theme_minimal()
Q1=quantile(na.omit(credit$V11),0.25)
Q3=quantile(na.omit(credit$V11),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosV11=na.omit(credit$V11)[na.omit(credit$V11)<limiteInferior | na.omit(credit$V11)>limiteSuperior]
percAtipicos=100*length(atipicosV11)/length((na.omit(credit$V11)))
print(paste("El porcentaje de datos atípicos es = ",percAtipicos))
ggplot(credit, aes(x = V11)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
labs(title = "Histograma de la Variable V11", x = "V11(original)", y = "Frecuencia") +
theme_minimal()
ggplot(credit, aes(y = V11)) +
geom_boxplot(fill = "skyblue", color = "darkblue", outlier.color = "red", outlier.shape = 16) +
labs(title = "Boxplot de V11", y = "V11", x = "") +
theme_minimal()
Q1=quantile(na.omit(credit$V15),0.25)
Q3=quantile(na.omit(credit$V15),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosV15=na.omit(credit$V15)[na.omit(credit$V15)<limiteInferior | na.omit(credit$V15)>limiteSuperior]
percAtipicos=100*length(atipicosV15)/length((na.omit(credit$V15)))
print(paste("El porcentaje de datos atípicos es = ",percAtipicos))
ggplot(credit, aes(x = V15)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
labs(title = "Histograma de la Variable V15", x = "V15", y = "Frecuencia") +
theme_minimal()
ggplot(credit, aes(y = V15)) +
geom_boxplot(fill = "skyblue", color = "darkblue", outlier.color = "red", outlier.shape = 16) +
labs(title = "Boxplot de V15", y = "V15", x = "") +
theme_minimal()
credit.trainIdx<-readRDS("credit.trainIdx")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Train[!complete.cases(credit.Datos.Train),])
# Visualización rápida de la matriz de correlación en forma de símbolos
symnum(cor(credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)], use = "complete.obs"))
preproc <- preProcess(credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)], method = "medianImpute")
credit_num_imputed <- predict(preproc, credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)])
# Verificar que no hay valores nulos en el nuevo dataframe
sum(is.na(credit_num_imputed))
credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)] <- credit_num_imputed
imputar_moda <- function(x) {
if (is.factor(x) || is.character(x)) {
# Calcular la moda (valor más frecuente)
moda <- names(sort(table(x), decreasing = TRUE))[1]
# Reemplazar los NA con la moda
x[is.na(x)] <- moda
}
return(x)
}
credit.Datos.Train <- data.frame(lapply(credit.Datos.Train, imputar_moda))
#Comprobar que todo ha ido bien
nrow(credit.Datos.Train[!complete.cases(credit.Datos.Train),])
credit.Datos.Train[!complete.cases(credit.Datos.Train),]
nearZeroVar(credit.Datos.Train)
symnum(cor(credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)]))
credit.Datos.Train.Normalizados=credit.Datos.Train
# Aplicar preProcess para centrar en la mediana y escalar por el RIC
preproc <- preProcess(credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")], method = c("center", "scale"),
center = apply(credit.Datos.Train[, c("V8", "V11", "V15")], 2, median),
scale = apply(credit.Datos.Train[, c("V8", "V11", "V15")], 2, IQR))
credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")] <- predict(preproc, credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")])
# Verificar los resultados
head(credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")])
credit.Datos.Train.Normalizados$V2=log1p(credit.Datos.Train.Normalizados$V2)
credit.Datos.Train.Normalizados$V3=log1p(credit.Datos.Train.Normalizados$V3)
credit.Datos.Train.Normalizados$V14=log1p(credit.Datos.Train.Normalizados$V14)
min_max_normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
credit.Datos.Train.Normalizados$V2=min_max_normalize(credit.Datos.Train.Normalizados$V2)
credit.Datos.Train.Normalizados$V3=min_max_normalize(credit.Datos.Train.Normalizados$V3)
credit.Datos.Train.Normalizados$V14=min_max_normalize(credit.Datos.Train.Normalizados$V14)
summary(credit.Datos.Train.Normalizados[, c("V2", "V3", "V14")])
credit.Datos.Test.Normalizados=credit.Datos.Test
credit.Datos.Test.Normalizados$V2=log1p(credit.Datos.Test.Normalizados$V2)
credit.Datos.Test.Normalizados$V3=log1p(credit.Datos.Test.Normalizados$V3)
credit.Datos.Test.Normalizados$V14=log1p(credit.Datos.Test.Normalizados$V14)
credit.Datos.Test.Normalizados$V2=min_max_normalize(credit.Datos.Test.Normalizados$V2)
credit.Datos.Test.Normalizados$V3=min_max_normalize(credit.Datos.Test.Normalizados$V3)
credit.Datos.Test.Normalizados$V14=min_max_normalize(credit.Datos.Test.Normalizados$V14)
#Utilizamos la variable 'prepoc' creada anteriormente con los datos de TRAIN para evitar peaking
credit.Datos.Test.Normalizados[, c("V8", "V11", "V15")] <- predict(preproc, credit.Datos.Test.Normalizados[, c("V8", "V11", "V15")])
predictors <- credit.Datos.Train[, -which(names(credit.Datos.Train) == "V16")]
target <- credit.Datos.Train$V16
rf_model <- randomForest(x = predictors, y = target, importance = TRUE)
importance_rf <- importance(rf_model)
varImpPlot(rf_model)
credit.Datos.Train.Rf=credit.Datos.Train
credit.Datos.Train.Rf$V2=log1p(credit.Datos.Train.Rf$V2)
credit.Datos.Train.Rf$V3=log1p(credit.Datos.Train.Rf$V3)
credit.Datos.Train.Rf$V8=log1p(credit.Datos.Train.Rf$V8)
credit.Datos.Train.Rf$V11=log1p(credit.Datos.Train.Rf$V11)
credit.Datos.Train.Rf$V14=log1p(credit.Datos.Train.Rf$V14)
credit.Datos.Train.Rf$V15=log1p(credit.Datos.Train.Rf$V15)
ggplot(credit.Datos.Train, aes(x = V2)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
labs(title = "Histograma de V2", x = "V2", y = "Frecuencia") +
theme_minimal()
credit.Datos.Test.Rf=credit.Datos.Test
credit.Datos.Test.Rf$V2=log1p(credit.Datos.Test.Rf$V2)
credit.Datos.Test.Rf$V3=log1p(credit.Datos.Test.Rf$V3)
credit.Datos.Test.Rf$V8=log1p(credit.Datos.Test.Rf$V8)
credit.Datos.Test.Rf$V11=log1p(credit.Datos.Test.Rf$V11)
credit.Datos.Test.Rf$V14=log1p(credit.Datos.Test.Rf$V14)
credit.Datos.Test.Rf$V15=log1p(credit.Datos.Test.Rf$V15)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
print(modelo_rf_cv)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
modelo_nnet <- train(
V16 ~ .,                           # Reemplaza `Target` con tu variable objetivo
data = credit.Datos.Train.Normalizados,
method = "nnet",
trControl = control,
tuneLength = 5,
trace = FALSE
)
print(modelo_nnet)
predicciones <- predict(modelo_nnet, credit.Datos.Test.Normalizados) # Reemplaza con tu conjunto de test
confusionMatrix(predicciones, credit.Datos.Test$V16)
library(caret)
# Definir un grid de hiperparámetros
grid <- expand.grid(
size = c(1, 3, 5, 7),              # Nodos en la capa oculta
decay = c(1e-05, 1e-04, 1e-03, 1e-02) # Regularización
)
# Crear un data frame para almacenar resultados
resultados <- data.frame(size = numeric(),
decay = numeric(),
precision_test = numeric())
# Loop para probar cada combinación del grid
for (i in 1:nrow(grid)) {
size <- grid$size[i]
decay <- grid$decay[i]
# Entrenar el modelo con los hiperparámetros actuales
set.seed(123)
modelo <- train(
V16 ~ .,
data = credit.Datos.Train,
method = "nnet",
trControl = trainControl(method = "none"), # Sin validación cruzada, entrenamos directamente
tuneGrid = expand.grid(size = size, decay = decay),
trace = FALSE
)
# Predicciones en el conjunto de test
predicciones <- predict(modelo, newdata = credit.Datos.Test)
# Calcular precisión sobre el conjunto de test usando confusionMatrix
conf_matrix <- confusionMatrix(predicciones, credit.Datos.Test$V16)
precision_test <- conf_matrix$overall["Accuracy"]  # Extraer la precisión
# Almacenar resultados
resultados <- rbind(resultados, data.frame(size = size, decay = decay, precision_test = precision_test))
}
# Ordenar resultados por precisión descendente
resultados <- resultados[order(-resultados$precision_test), ]
print(resultados)
mejores_parametros <- resultados[1, ] # Mejor combinación según el test
size_mejor <- mejores_parametros$size
decay_mejor <- mejores_parametros$decay
set.seed(123)
modelo_final <- train(
V16 ~ .,
data = credit.Datos.Train,
method = "nnet",
trControl = trainControl(method = "none"),
tuneGrid = expand.grid(size = size_mejor, decay = decay_mejor),
trace = FALSE
)
# Evaluar el modelo final en el conjunto de test
predicciones_final <- predict(modelo_final, newdata = credit.Datos.Test)
confusionMatrix(predicciones_final, credit.Datos.Test$V16)
set.seed(1234)
knn_model <- train(
V16 ~ .,                          # Reemplaza `V16` con tu variable objetivo
data = credit.Datos.Train.Normalizados,
method = "knn",
trControl = control,
tuneLength = 10                   # Ajusta automáticamente k en un rango de 10 valores
)
print(knn_model)
# Realizar predicciones en el conjunto de prueba
knn_predictions <- predict(knn_model, newdata = credit.Datos.Test.Normalizados)
# Calcular la matriz de confusión
confusionMatrix(knn_predictions, credit.Datos.Test.Normalizados$V16)
set.seed(1234)
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)
print(gbm_model)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_model, newdata = credit.Datos.Test.Normalizados)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.Normalizados$V16)
modelLookup(("gbm"))
# Establecer un control de entrenamiento con validación cruzada de 10 pliegues
control <- trainControl(method = "cv", number = 10)
# Definir un grid de búsqueda más amplio para mejorar la precisión
tuneGrid <- expand.grid(
n.trees = seq(100, 1000, by = 100),              # Número de árboles
interaction.depth = seq(1, 5, by = 1),           # Profundidad del árbol
shrinkage = c(0.05, 0.1, 0.2, 0.3),              # Tasa de aprendizaje
n.minobsinnode = c(5, 10, 15)                    # Mínimo de observaciones en nodo final
)
# Entrenar el modelo gbm usando el grid de hiperparámetros
set.seed(123)
modelo_gbm <- train(
V16 ~ .,
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneGrid = tuneGrid,
verbose = FALSE
)
# Ver los mejores hiperparámetros encontrados
print(modelo_gbm)
modelLookup(("nnet"))
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ V2,V3,V4,V5,V6,V7,V8,V9,V10,V11,V13,V14,V15,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
View(credit.Datos.Train.Rf)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ V2,V4,V5,V6,V7,V8,V9,V10,V11,V13,V14,V15,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V13 + V14 + V15,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
print(modelo_rf_cv)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V13 + V14 + V15,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
print(modelo_rf_cv)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ V12 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V13 + V14 + V15,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ V12 + V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V13 + V14 + V15,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V13 + V14 + V15,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf[,c("V2","V3","V4","V5","V6","V7","V8","V9","V10","V11","V13","V14","V15")])
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf[,c("V1","V2","V3","V4","V5","V6","V7","V8","V9","V10","V11","V13","V12","V14","V15")])
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf[,c("V1","V2","V3","V4","V5","V6","V7","V8","V9","V10","V11","V13","V12","V14","V15")])
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V13 + V14 + V15,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf[,c("V1","V2","V3","V4","V5","V6","V7","V8","V9","V10","V11","V13","V14","V15")])
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ V1 + V2 + V3 + V4 + V5 + V6 + V7 + V8  + V10 + V11 + V12 + V13 + V14 + V15,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf[,c("V1","V2","V3","V4","V5","V6","V7","V8","V10","V11","V12","V13","V14","V15")])
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
varImp(modelo_nnet)
varImpPlot(modelo_nnet)
varImpPlot(modelo_nnet)
varImp(modelo_final)
varImp(knn_model)
varImp(gbm_model)
set.seed(1234)
supressWarnings({
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
))})
set.seed(1234)
supressWarnings({
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)})
set.seed(1234)
suppressWarnings({
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)})
set.seed(1234)
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)
set.seed(1234)
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)
# Calcular la importancia de las variables
importancia <- varImp(gbm_model)
summary(gbm_model)
set.seed(1234)
suppressWarnings({
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)})
# Calcular la importancia de las variables directamente desde gbm
importancia_directa <- summary(gbm_model$finalModel)  # Si entrenaste con caret
print(importancia_directa)
# Visualizar las 10 variables más importantes
head(importancia_directa, 10)
# Calcular la importancia de las variables directamente desde gbm
importancia_directa <- summary(gbm_model$finalModel)  # Si entrenaste con caret
credit.Datos.Train.gbm = credit.Datos.Train
credit.Datos.Test.gbm = credit.Datos.Test
# Eliminar las columnas específicas por nombre
credit.Datos.Train.gbm <- credit.Datos.Train.gbm[, !colnames(credit.Datos.Train.gbm) %in% c("V4", "V6", "V13")]
credit.Datos.Test.gbm <- credit.Datos.Test.gbm[, !colnames(credit.Datos.Test.gbm) %in% c("V4", "V6", "V13")]
View(credit.Datos.Train.Normalizados)
set.seed(1234)
suppressWarnings({
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.gbm,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)})
print(gbm_model)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_model, newdata = credit.Datos.Test.gbm)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.gbm$V16)
