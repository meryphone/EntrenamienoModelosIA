RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosv14=na.omit(credit$V14)[na.omit(credit$V14)<limiteInferior | na.omit(credit$V14)>limiteSuperior]
percAtipicos=100*length(atipicosv14)/length((na.omit(credit$V14)))
print(paste("El porcentaje de datos atípicos para V14 es = ",percAtipicos))
Q1=quantile(na.omit(credit$V8),0.25)
Q3=quantile(na.omit(credit$V8),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosv8=na.omit(credit$V8)[na.omit(credit$V8)<limiteInferior | na.omit(credit$V8)>limiteSuperior]
percAtipicos=100*length(atipicosv8)/length((na.omit(credit$V8)))
print(paste("El porcentaje de datos atípicos es = ",percAtipicos))
ggplot(credit, aes(x = V8)) +
geom_histogram(bins = 30, fill = "orange", color = "black", alpha = 0.7) +
labs(title = "Histograma de V8 original", x = "V8 (original)", y = "Frecuencia")
ggplot(credit, aes(y = V8)) +
geom_boxplot(fill = "skyblue", color = "darkblue", outlier.color = "red", outlier.shape = 16) +
labs(title = "Boxplot de V8", y = "V8", x = "") +
theme_minimal()
Q1=quantile(na.omit(credit$V11),0.25)
Q3=quantile(na.omit(credit$V11),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosV11=na.omit(credit$V11)[na.omit(credit$V11)<limiteInferior | na.omit(credit$V11)>limiteSuperior]
percAtipicos=100*length(atipicosV11)/length((na.omit(credit$V11)))
print(paste("El porcentaje de datos atípicos es = ",percAtipicos))
ggplot(credit, aes(x = V11)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
labs(title = "Histograma de la Variable V11", x = "V11(original)", y = "Frecuencia") +
theme_minimal()
ggplot(credit, aes(y = V11)) +
geom_boxplot(fill = "skyblue", color = "darkblue", outlier.color = "red", outlier.shape = 16) +
labs(title = "Boxplot de V11", y = "V11", x = "") +
theme_minimal()
Q1=quantile(na.omit(credit$V15),0.25)
Q3=quantile(na.omit(credit$V15),0.75)
RIC=Q3-Q1
limiteInferior=Q1-1.5*RIC
limiteSuperior=Q3+1.5*RIC
atipicosV15=na.omit(credit$V15)[na.omit(credit$V15)<limiteInferior | na.omit(credit$V15)>limiteSuperior]
percAtipicos=100*length(atipicosV15)/length((na.omit(credit$V15)))
print(paste("El porcentaje de datos atípicos es = ",percAtipicos))
ggplot(credit, aes(x = V15)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
labs(title = "Histograma de la Variable V15", x = "V15", y = "Frecuencia") +
theme_minimal()
ggplot(credit, aes(y = V15)) +
geom_boxplot(fill = "skyblue", color = "darkblue", outlier.color = "red", outlier.shape = 16) +
labs(title = "Boxplot de V15", y = "V15", x = "") +
theme_minimal()
credit.trainIdx<-readRDS("credit.trainIdx")
credit.Datos.Train<-credit[credit.trainIdx,]
credit.Datos.Test<-credit[-credit.trainIdx,]
nrow(credit.Datos.Train)
nrow(credit.Datos.Train[!complete.cases(credit.Datos.Train),])
# Visualización rápida de la matriz de correlación en forma de símbolos
symnum(cor(credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)], use = "complete.obs"))
preproc <- preProcess(credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)], method = "medianImpute")
credit_num_imputed <- predict(preproc, credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)])
# Verificar que no hay valores nulos en el nuevo dataframe
sum(is.na(credit_num_imputed))
credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)] <- credit_num_imputed
imputar_moda <- function(x) {
if (is.factor(x) || is.character(x)) {
# Calcular la moda (valor más frecuente)
moda <- names(sort(table(x), decreasing = TRUE))[1]
# Reemplazar los NA con la moda
x[is.na(x)] <- moda
}
return(x)
}
credit.Datos.Train <- data.frame(lapply(credit.Datos.Train, imputar_moda))
#Comprobar que todo ha ido bien
nrow(credit.Datos.Train[!complete.cases(credit.Datos.Train),])
credit.Datos.Train[!complete.cases(credit.Datos.Train),]
nearZeroVar(credit.Datos.Train)
symnum(cor(credit.Datos.Train[, sapply(credit.Datos.Train, is.numeric)]))
credit.Datos.Train.Normalizados=credit.Datos.Train
# Aplicar preProcess para centrar en la mediana y escalar por el RIC
preproc <- preProcess(credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")], method = c("center", "scale"),
center = apply(credit.Datos.Train[, c("V8", "V11", "V15")], 2, median),
scale = apply(credit.Datos.Train[, c("V8", "V11", "V15")], 2, IQR))
credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")] <- predict(preproc, credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")])
# Verificar los resultados
head(credit.Datos.Train.Normalizados[, c("V8", "V11", "V15")])
credit.Datos.Train.Normalizados$V2=log1p(credit.Datos.Train.Normalizados$V2)
credit.Datos.Train.Normalizados$V3=log1p(credit.Datos.Train.Normalizados$V3)
credit.Datos.Train.Normalizados$V14=log1p(credit.Datos.Train.Normalizados$V14)
min_max_normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
credit.Datos.Train.Normalizados$V2=min_max_normalize(credit.Datos.Train.Normalizados$V2)
credit.Datos.Train.Normalizados$V3=min_max_normalize(credit.Datos.Train.Normalizados$V3)
credit.Datos.Train.Normalizados$V14=min_max_normalize(credit.Datos.Train.Normalizados$V14)
summary(credit.Datos.Train.Normalizados[, c("V2", "V3", "V14")])
credit.Datos.Test.Normalizados=credit.Datos.Test
credit.Datos.Test.Normalizados$V2=log1p(credit.Datos.Test.Normalizados$V2)
credit.Datos.Test.Normalizados$V3=log1p(credit.Datos.Test.Normalizados$V3)
credit.Datos.Test.Normalizados$V14=log1p(credit.Datos.Test.Normalizados$V14)
credit.Datos.Test.Normalizados$V2=min_max_normalize(credit.Datos.Test.Normalizados$V2)
credit.Datos.Test.Normalizados$V3=min_max_normalize(credit.Datos.Test.Normalizados$V3)
credit.Datos.Test.Normalizados$V14=min_max_normalize(credit.Datos.Test.Normalizados$V14)
#Utilizamos la variable 'prepoc' creada anteriormente con los datos de TRAIN para evitar peaking
credit.Datos.Test.Normalizados[, c("V8", "V11", "V15")] <- predict(preproc, credit.Datos.Test.Normalizados[, c("V8", "V11", "V15")])
predictors <- credit.Datos.Train[, -which(names(credit.Datos.Train) == "V16")]
target <- credit.Datos.Train$V16
rf_model <- randomForest(x = predictors, y = target, importance = TRUE)
importance_rf <- importance(rf_model)
varImpPlot(rf_model)
credit.Datos.Train.Rf=credit.Datos.Train
credit.Datos.Train.Rf$V2=log1p(credit.Datos.Train.Rf$V2)
credit.Datos.Train.Rf$V3=log1p(credit.Datos.Train.Rf$V3)
credit.Datos.Train.Rf$V8=log1p(credit.Datos.Train.Rf$V8)
credit.Datos.Train.Rf$V11=log1p(credit.Datos.Train.Rf$V11)
credit.Datos.Train.Rf$V14=log1p(credit.Datos.Train.Rf$V14)
credit.Datos.Train.Rf$V15=log1p(credit.Datos.Train.Rf$V15)
ggplot(credit.Datos.Train, aes(x = V2)) +
geom_histogram(binwidth = 5, fill = "skyblue", color = "black") +
labs(title = "Histograma de V2", x = "V2", y = "Frecuencia") +
theme_minimal()
credit.Datos.Test.Rf=credit.Datos.Test
credit.Datos.Test.Rf$V2=log1p(credit.Datos.Test.Rf$V2)
credit.Datos.Test.Rf$V3=log1p(credit.Datos.Test.Rf$V3)
credit.Datos.Test.Rf$V8=log1p(credit.Datos.Test.Rf$V8)
credit.Datos.Test.Rf$V11=log1p(credit.Datos.Test.Rf$V11)
credit.Datos.Test.Rf$V14=log1p(credit.Datos.Test.Rf$V14)
credit.Datos.Test.Rf$V15=log1p(credit.Datos.Test.Rf$V15)
set.seed(1234)
control <- trainControl(method = "cv", number = 10)
modelo_rf_cv <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneLength = 5
)
print(modelo_rf_cv)
predicciones <- predict(modelo_rf_cv, newdata = credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
# Cargar los paquetes necesarios
library(caret)
library(randomForest)
# Configurar la semilla para reproducibilidad
set.seed(1234)
# Definir el control de entrenamiento con validación cruzada
control <- trainControl(
method = "cv",          # Usar validación cruzada
number = 10,            # Número de particiones (10-fold CV)
search = "grid"         # Realizar una búsqueda en malla
)
# Definir la malla de hiperparámetros solo para mtry
tune_grid <- expand.grid(
mtry = c(2, 4, 6, 8, 10, 12)       # Número de variables a considerar en cada split
)
# Entrenar el modelo usando la búsqueda de hiperparámetros solo con mtry
modelo_rf <- train(
V16 ~ .,                                # Fórmula del modelo
data = credit.Datos.Train.Rf, # Conjunto de datos de entrenamiento
method = "rf",                          # Especificar Random Forest como método
trControl = control,                    # Control de entrenamiento con CV
tuneGrid = tune_grid,                   # Malla de hiperparámetros solo para mtry
ntree = 1000                            # Número de árboles configurado directamente
)
# Mostrar los resultados del modelo
print(modelo_rf)
# Ver los hiperparámetros óptimos y precisión obtenida
cat("Mejores hiperparámetros:\n")
print(modelo_rf$bestTune)
cat("\nPrecisión obtenida con los mejores hiperparámetros:", max(modelo_rf$results$Accuracy), "\n")
# Ver la matriz de confusión en el conjunto de entrenamiento
predicciones <- predict(modelo_rf, newdata=credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
# Configurar los mejores hiperparámetros encontrados
best_mtry <- 11
best_ntree <- 1000
best_nodesize <- 5
# Entrenar el modelo con los hiperparámetros óptimos en el conjunto de entrenamiento
library(randomForest)
set.seed(1234)
rf_final_model <- randomForest(
V16 ~ .,
data = credit.Datos.Train.Rf,
mtry = best_mtry,
ntree = best_ntree,
nodesize = best_nodesize
)
# Predecir en el conjunto de prueba
predictions <- predict(rf_final_model, credit.Datos.Test)
# Crear una matriz de confusión para evaluar el rendimiento
confusion_matrix <- table(Predicted = predictions, Actual = credit.Datos.Test$V16)
# Calcular la precisión
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
# Mostrar los resultados
cat("\nMatriz de confusión:\n")
print(confusion_matrix)
cat("\nPrecisión en el conjunto de prueba:", accuracy, "\n")
set.seed(1234)
modelo_nnet <- train(
V16 ~ .,                           # Reemplaza `Target` con tu variable objetivo
data = credit.Datos.Train.Normalizados,
method = "nnet",
trControl = control,
tuneLength = 5,
trace = FALSE
)
print(modelo_nnet)
predicciones <- predict(modelo_nnet, credit.Datos.Test.Normalizados) # Reemplaza con tu conjunto de test
confusionMatrix(predicciones, credit.Datos.Test$V16)
set.seed(1234)
knn_model <- train(
V16 ~ .,                          # Reemplaza `V16` con tu variable objetivo
data = credit.Datos.Train.Normalizados,
method = "knn",
trControl = control,
tuneLength = 10                   # Ajusta automáticamente k en un rango de 10 valores
)
print(knn_model)
# Realizar predicciones en el conjunto de prueba
knn_predictions <- predict(knn_model, newdata = credit.Datos.Test.Normalizados)
# Calcular la matriz de confusión
confusionMatrix(knn_predictions, credit.Datos.Test.Normalizados$V16)
set.seed(1234)
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)
print(gbm_model)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_model, newdata = credit.Datos.Test.Normalizados)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.Normalizados$V16)
modelLookup(("gbm"))
# Establecer un control de entrenamiento con validación cruzada de 10 pliegues
control <- trainControl(method = "cv", number = 10)
# Definir un grid de búsqueda más amplio para mejorar la precisión
tuneGrid <- expand.grid(
n.trees = seq(100, 1000, by = 100),              # Número de árboles
interaction.depth = seq(1, 5, by = 1),           # Profundidad del árbol
shrinkage = c(0.05, 0.1, 0.2, 0.3),              # Tasa de aprendizaje
n.minobsinnode = c(5, 10, 15)                    # Mínimo de observaciones en nodo final
)
# Entrenar el modelo gbm usando el grid de hiperparámetros
set.seed(123)
modelo_gbm <- train(
V16 ~ .,
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneGrid = tuneGrid,
verbose = FALSE
)
# Ver los mejores hiperparámetros encontrados
print(modelo_gbm)
# Evaluar el modelo con el conjunto de prueba
pred <- predict(modelo_gbm, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(pred, credit.Datos.Test.Normalizados$V16)
library(caret)
# Definir un grid de hiperparámetros
grid <- expand.grid(
mtry = c(2, 3, 4, 5),           # Número de predictores a considerar en cada división
ntree = c(100, 200, 500),       # Número de árboles
nodesize = c(1, 5, 10)          # Número mínimo de observaciones en un nodo terminal
)
# Control de validación cruzada
control <- trainControl(method = "cv", number = 5)  # Validación cruzada de 5 pliegues
# Entrenar el modelo
set.seed(123)
modelo_rf <- train(
V16 ~ .,                         # Fórmula del modelo
data = credit.Datos.Train,       # Datos de entrenamiento
method = "rf",                   # Algoritmo Random Forest
trControl = control,             # Control de validación
tuneGrid = grid,                 # Grid de hiperparámetros
importance = TRUE                # Calcular importancia de las variables
)
library(caret)
# Definir un grid válido solo con `mtry`
grid <- expand.grid(
mtry = c(2, 3, 4, 5)  # Número de predictores considerados en cada división
)
# Control de validación cruzada
control <- trainControl(method = "cv", number = 5)  # Validación cruzada de 5 pliegues
# Entrenar el modelo
set.seed(123)
modelo_rf <- train(
V16 ~ .,                         # Fórmula del modelo
data = credit.Datos.Train,       # Datos de entrenamiento
method = "rf",                   # Algoritmo Random Forest
trControl = control,             # Control de validación
tuneGrid = grid,                 # Grid de hiperparámetros
importance = TRUE                # Calcular importancia de las variables
)
# Resultados
print(modelo_rf)
plot(modelo_rf)
# Ver la matriz de confusión en el conjunto de entrenamiento
predicciones <- predict(modelo_rf, newdata=credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
modelo_nnet <- train(
V16 ~ .,                           # Reemplaza `Target` con tu variable objetivo
data = credit.Datos.Train.Normalizados,
method = "nnet",
trControl = control,
tuneLength = 5,
trace = FALSE
)
print(modelo_nnet)
predicciones <- predict(modelo_nnet, credit.Datos.Test.Normalizados) # Reemplaza con tu conjunto de test
confusionMatrix(predicciones, credit.Datos.Test$V16)
set.seed(1234)
modelo_nnet <- train(
V16 ~ .,                           # Reemplaza `Target` con tu variable objetivo
data = credit.Datos.Train.Normalizados,
method = "nnet",
trControl = control,
tuneLength = 5,
trace = FALSE
)
print(modelo_nnet)
predicciones <- predict(modelo_nnet, credit.Datos.Test.Normalizados) # Reemplaza con tu conjunto de test
confusionMatrix(predicciones, credit.Datos.Test$V16)
set.seed(1234)
knn_model <- train(
V16 ~ .,                          # Reemplaza `V16` con tu variable objetivo
data = credit.Datos.Train.Normalizados,
method = "knn",
trControl = control,
tuneLength = 10                   # Ajusta automáticamente k en un rango de 10 valores
)
print(knn_model)
# Realizar predicciones en el conjunto de prueba
knn_predictions <- predict(knn_model, newdata = credit.Datos.Test.Normalizados)
# Calcular la matriz de confusión
confusionMatrix(knn_predictions, credit.Datos.Test.Normalizados$V16)
set.seed(1234)
gbm_model <- train(
V16 ~ .,                        # Reemplaza `V16` con tu variable objetivo si es diferente
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneLength = 5,
verbose = FALSE                 # Evita imprimir detalles durante el entrenamiento
)
print(gbm_model)
# Realizar predicciones en el conjunto de prueba
gbm_predictions <- predict(gbm_model, newdata = credit.Datos.Test.Normalizados)
# Calcular la matriz de confusión
confusionMatrix(gbm_predictions, credit.Datos.Test.Normalizados$V16)
library(caret)
# Definir un grid de hiperparámetros
grid <- expand.grid(
size = c(1, 3, 5, 7),               # Número de nodos en la capa oculta
decay = c(1e-05, 1e-04, 1e-03, 1e-02) # Parámetros de regularización
)
# Control de validación cruzada
control <- trainControl(method = "cv", number = 5)  # Validación cruzada de 5 pliegues
# Entrenar el modelo
set.seed(123)
modelo_nn <- train(
V16 ~ .,                         # Fórmula del modelo
data = credit.Datos.Train.Normalizados,       # Conjunto de datos de entrenamiento
method = "nnet",                 # Algoritmo de redes neuronales
trControl = control,             # Configuración de validación cruzada
tuneGrid = grid,                 # Grid de hiperparámetros
trace = FALSE                    # Desactivar salida de la consola para `nnet`
)
# Ver los resultados
print(modelo_nn)
plot(modelo_nn)
# Mejor configuración encontrada
print(modelo_nn$bestTune)
predicciones <- predict(modelo_nnet, credit.Datos.Test.Normalizados) # Reemplaza con tu conjunto de test
confusionMatrix(predicciones, credit.Datos.Test$V16)
library(caret)
# Definir un grid de hiperparámetros
grid <- expand.grid(
size = c(1, 3, 5, 7),              # Nodos en la capa oculta
decay = c(1e-05, 1e-04, 1e-03, 1e-02) # Regularización
)
# Crear un data frame para almacenar resultados
resultados <- data.frame(size = numeric(),
decay = numeric(),
precision_test = numeric())
# Loop para probar cada combinación del grid
for (i in 1:nrow(grid)) {
size <- grid$size[i]
decay <- grid$decay[i]
# Entrenar el modelo con los hiperparámetros actuales
set.seed(123)
modelo <- train(
V16 ~ .,
data = credit.Datos.Train,
method = "nnet",
trControl = trainControl(method = "none"), # Sin validación cruzada, entrenamos directamente
tuneGrid = expand.grid(size = size, decay = decay),
trace = FALSE
)
# Predicciones en el conjunto de test
predicciones <- predict(modelo, newdata = credit.Datos.Test)
# Calcular precisión sobre el conjunto de test
precision_test <- sum(predicciones == credit.Datos.Test$V16) / nrow(credit.Datos.Test)
# Almacenar resultados
resultados <- rbind(resultados, data.frame(size = size, decay = decay, precision_test = precision_test))
}
# Ordenar resultados por precisión descendente
resultados <- resultados[order(-resultados$precision_test), ]
print(resultados)
mejores_parametros <- resultados[1, ] # Mejor combinación según el test
size_mejor <- mejores_parametros$size
decay_mejor <- mejores_parametros$decay
set.seed(123)
modelo_final <- train(
V16 ~ .,
data = credit.Datos.Train,
method = "nnet",
trControl = trainControl(method = "none"),
tuneGrid = expand.grid(size = size_mejor, decay = decay_mejor),
trace = FALSE
)
# Evaluar el modelo final en el conjunto de test
predicciones_final <- predict(modelo_final, newdata = credit.Datos.Test)
precision_final <- sum(predicciones_final == credit.Datos.Test$V16) / nrow(credit.Datos.Test)
print(precision_final)
mejores_parametros <- resultados[1, ] # Mejor combinación según el test
size_mejor <- mejores_parametros$size
decay_mejor <- mejores_parametros$decay
set.seed(123)
modelo_final <- train(
V16 ~ .,
data = credit.Datos.Train,
method = "nnet",
trControl = trainControl(method = "none"),
tuneGrid = expand.grid(size = size_mejor, decay = decay_mejor),
trace = FALSE
)
# Evaluar el modelo final en el conjunto de test
predicciones_final <- predict(modelo_final, newdata = credit.Datos.Test)
confusionMatrix(predicciones, credit.Datos.Test$V16)
print(precision_final)
library(caret)
# Definir un grid de hiperparámetros
grid <- expand.grid(
size = c(1, 3, 5, 7),              # Nodos en la capa oculta
decay = c(1e-05, 1e-04, 1e-03, 1e-02) # Regularización
)
# Crear un data frame para almacenar resultados
resultados <- data.frame(size = numeric(),
decay = numeric(),
precision_test = numeric())
# Loop para probar cada combinación del grid
for (i in 1:nrow(grid)) {
size <- grid$size[i]
decay <- grid$decay[i]
# Entrenar el modelo con los hiperparámetros actuales
set.seed(123)
modelo <- train(
V16 ~ .,
data = credit.Datos.Train,
method = "nnet",
trControl = trainControl(method = "none"), # Sin validación cruzada, entrenamos directamente
tuneGrid = expand.grid(size = size, decay = decay),
trace = FALSE
)
# Predicciones en el conjunto de test
predicciones <- predict(modelo, newdata = credit.Datos.Test)
# Calcular precisión sobre el conjunto de test usando confusionMatrix
conf_matrix <- confusionMatrix(predicciones, credit.Datos.Test$V16)
precision_test <- conf_matrix$overall["Accuracy"]  # Extraer la precisión
# Almacenar resultados
resultados <- rbind(resultados, data.frame(size = size, decay = decay, precision_test = precision_test))
}
# Ordenar resultados por precisión descendente
resultados <- resultados[order(-resultados$precision_test), ]
print(resultados)
mejores_parametros <- resultados[1, ] # Mejor combinación según el test
size_mejor <- mejores_parametros$size
decay_mejor <- mejores_parametros$decay
set.seed(123)
modelo_final <- train(
V16 ~ .,
data = credit.Datos.Train,
method = "nnet",
trControl = trainControl(method = "none"),
tuneGrid = expand.grid(size = size_mejor, decay = decay_mejor),
trace = FALSE
)
# Evaluar el modelo final en el conjunto de test
predicciones_final <- predict(modelo_final, newdata = credit.Datos.Test)
confusionMatrix(predicciones, credit.Datos.Test$V16)
mejores_parametros <- resultados[1, ] # Mejor combinación según el test
size_mejor <- mejores_parametros$size
decay_mejor <- mejores_parametros$decay
set.seed(123)
modelo_final <- train(
V16 ~ .,
data = credit.Datos.Train,
method = "nnet",
trControl = trainControl(method = "none"),
tuneGrid = expand.grid(size = size_mejor, decay = decay_mejor),
trace = FALSE
)
# Evaluar el modelo final en el conjunto de test
predicciones_final <- predict(modelo_final, newdata = credit.Datos.Test)
confusionMatrix(predicciones_final, credit.Datos.Test$V16)
