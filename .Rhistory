# Configurar control de entrenamiento
control <- trainControl(
method = "cv",                      # Validación cruzada
number = 5,                         # Número de folds en la validación cruzada
search = "grid"                     # Tipo de búsqueda: "grid" para búsqueda exhaustiva
)
# Entrenar el modelo gbm con búsqueda de hiperparámetros
modelo_gbm <- train(
V16 ~ .,                            # Fórmula del modelo
data = credit.Datos.Train.Rf,       # Conjunto de datos
method = "gbm",                     # Método de modelado
trControl = control,                # Control de entrenamiento
tuneGrid = grid,                    # Cuadrícula de hiperparámetros
verbose = FALSE                     # Desactivar mensajes de progreso de gbm
)
# Ver los mejores hiperparámetros encontrados
print(modelo_gbm$bestTune)
# Fijamos una semilla para reproducibilidad
set.seed(1234)
# Definir la cuadrícula de hiperparámetros para el modelo gbm
grid <- expand.grid(
n.trees = c(50, 100, 150, 200, 300),
interaction.depth = c(1, 3, 5, 7),
shrinkage = c(0.01, 0.05, 0.1, 0.2),
n.minobsinnode = c(5, 10, 15, 20)
)
# Configurar control de entrenamiento
control <- trainControl(
method = "cv",                      # Validación cruzada
number = 5,                         # Número de folds en la validación cruzada
search = "grid"                     # Tipo de búsqueda: "grid" para búsqueda exhaustiva
)
# Entrenar el modelo gbm con búsqueda de hiperparámetros
modelo_gbm <- train(
V16 ~ .,                            # Fórmula del modelo
data = credit.Datos.Train.Normalizados,       # Conjunto de datos
method = "gbm",                     # Método de modelado
trControl = control,                # Control de entrenamiento
tuneGrid = grid,                    # Cuadrícula de hiperparámetros
verbose = FALSE                     # Desactivar mensajes de progreso de gbm
)
# Ver los mejores hiperparámetros encontrados
print(modelo_gbm$bestTune)
predicciones <- predict(modelo_ajustado, newdata = credit.Datos.Test.Normalizados)
predicciones <- predict(modelo_gbm$bestTune, newdata = credit.Datos.Test.Normalizados)
predicciones <- predict(modelo_gbm, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(predicciones, credit.Datos.Test.Normalizados$V16)  # Ajusta `V16` al nombre de tu variable objetivo
print(modelo_gbm)
# Fijamos una semilla para reproducibilidad
set.seed(1234)
# Definir la cuadrícula de hiperparámetros para el modelo gbm
# Configuración del grid para ajustar el modelo
grid <- expand.grid(
n.trees = seq(100, 1000, by = 100),          # Prueba un rango amplio de iteraciones
interaction.depth = seq(1, 10, by = 1),       # Profundidad del árbol
shrinkage = c(0.01, 0.05, 0.1, 0.15),         # Valores de aprendizaje bajos y moderados
n.minobsinnode = c(5, 10, 15, 20)             # Tamaño mínimo de nodo terminal
)
# Configuración del control de entrenamiento con validación cruzada
control <- trainControl(method = "cv", number = 10)
# Entrenamiento del modelo con búsqueda de hiperparámetros
set.seed(1234)
modelo_gbm <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "gbm",
trControl = control,
tuneGrid = grid,
metric = "Accuracy"                          # Optimizar por precisión
)
# Ver los mejores hiperparámetros encontrados
print(modelo_gbm$bestTune)
predicciones <- predict(modelo_gbm, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(predicciones, credit.Datos.Test.Normalizados$V16)  # Ajusta `V16` al nombre de tu variable objetivo
# Fijamos una semilla para reproducibilidad
set.seed(1234)
# Definir la cuadrícula de hiperparámetros para el modelo gbm
# Configuración del grid para ajustar el modelo
# Configuración del grid para ajustar el modelo GBM
grid <- expand.grid(
n.trees = seq(100, 500, by = 50),             # Reducimos el número máximo de árboles
interaction.depth = c(3, 4, 5, 6),            # Ajustamos la profundidad del árbol
shrinkage = c(0.05, 0.07, 0.1),               # Ajustamos la tasa de aprendizaje
n.minobsinnode = c(5, 7, 10)                  # Número mínimo de observaciones por nodo
)
# Control de validación cruzada
control <- trainControl(method = "cv", number = 10)
# Entrenamiento del modelo GBM con el grid ajustado
set.seed(1234)
modelo_gbm_optimizado <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "gbm",
trControl = control,
tuneGrid = grid,
metric = "Accuracy"
)
# Configuración del control de entrenamiento con validación cruzada
control <- trainControl(method = "cv", number = 10)
# Entrenamiento del modelo con búsqueda de hiperparámetros
set.seed(1234)
modelo_gbm <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "gbm",
trControl = control,
tuneGrid = grid,
metric = "Accuracy"                          # Optimizar por precisión
)
# Ver los mejores hiperparámetros encontrados
print(modelo_gbm$bestTune)
predicciones <- predict(modelo_gbm, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(predicciones, credit.Datos.Test.Normalizados$V16)  # Ajusta `V16` al nombre de tu variable objetivo
gbmInfo$grid
gbm$grid
getModeli
getModelI
getModelInfo(("gbm"))
# Definir un grid más amplio para optimizar el modelo GBM
tune_grid <- expand.grid(
n.trees = seq(300, 500, by = 50),             # Aumentamos el número de árboles
interaction.depth = seq(1, 5, by = 1),        # Exploramos profundidades mayores
shrinkage = c(0.05, 0.1, 0.15),               # Incluimos una tasa de aprendizaje más baja para un ajuste más fino
n.minobsinnode = c(5, 10, 15)                 # Exploramos diferentes valores para nodos terminales
)
# Ajustar el modelo con el nuevo grid
set.seed(1234)
modelo_gbm_tuned <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "gbm",
trControl = trainControl(method = "cv", number = 10),
tuneGrid = tune_grid
)
# Revisar los resultados
modelo_gbm_tuned$results
predicciones <- predict(modelo_gbm, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(predicciones, credit.Datos.Test.Normalizados$V16)  # Ajusta `V16` al nombre de tu variable objetivo
predicciones <- predict(modelo_gbm_tuned, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(predicciones, credit.Datos.Test.Normalizados$V16)  # Ajusta `V16` al nombre de tu variable objetivo
# Fijamos una semilla para reproducibilidad
set.seed(1234)
# Definir la cuadrícula de hiperparámetros para el modelo gbm
# Configuración del grid para ajustar el modelo
# Configuración del grid para ajustar el modelo GBM
grid <- expand.grid(
n.trees = seq(100, 500, by = 50),             # Reducimos el número máximo de árboles
interaction.depth = c(3, 4, 5, 6),            # Ajustamos la profundidad del árbol
shrinkage = c(0.05, 0.07, 0.1),               # Ajustamos la tasa de aprendizaje
n.minobsinnode = c(5, 7, 10)                  # Número mínimo de observaciones por nodo
)
# Control de validación cruzada
control <- trainControl(method = "cv", number = 10)
# Entrenamiento del modelo GBM con el grid ajustado
set.seed(1234)
modelo_gbm_optimizado <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "gbm",
trControl = control,
tuneGrid = grid,
metric = "Accuracy"
)
# Configuración del control de entrenamiento con validación cruzada
control <- trainControl(method = "cv", number = 10)
# Entrenamiento del modelo con búsqueda de hiperparámetros
set.seed(1234)
modelo_gbm <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "gbm",
trControl = control,
tuneGrid = grid,
metric = "Accuracy"                          # Optimizar por precisión
)
# Ver los mejores hiperparámetros encontrados
print(modelo_gbm_optimizado$bestTune)
predicciones <- predict(modelo_gbm_optimizado, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(predicciones, credit.Datos.Test.Normalizados$V16)  # Ajusta `V16` al nombre de tu variable objetivo
# Fijamos una semilla para reproducibilidad
set.seed(1234)
# Definir la cuadrícula de hiperparámetros para el modelo gbm
# Configuración del grid para ajustar el modelo
# Configuración del grid para ajustar el modelo GBM
grid <- expand.grid(
n.trees = seq(100, 500, by = 50),             # Reducimos el número máximo de árboles
interaction.depth = c(3, 4, 5, 6),            # Ajustamos la profundidad del árbol
shrinkage = c(0.05, 0.07, 0.1),               # Ajustamos la tasa de aprendizaje
n.minobsinnode = c(5, 7, 10)                  # Número mínimo de observaciones por nodo
)
# Control de validación cruzada
control <- trainControl(method = "cv", number = 10)
# Entrenamiento del modelo GBM con el grid ajustado
set.seed(1234)
modelo_gbm_optimizado <- train(
V16 ~ .,
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneGrid = grid,
metric = "Accuracy"
)
# Configuración del control de entrenamiento con validación cruzada
control <- trainControl(method = "cv", number = 10)
# Entrenamiento del modelo con búsqueda de hiperparámetros
set.seed(1234)
modelo_gbm <- train(
V16 ~ .,
data = credit.Datos.Train.Rf,
method = "gbm",
trControl = control,
tuneGrid = grid,
metric = "Accuracy"                          # Optimizar por precisión
)
# Ver los mejores hiperparámetros encontrados
print(modelo_gbm_optimizado$bestTune)
predicciones <- predict(modelo_gbm_optimizado, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(predicciones, credit.Datos.Test.Normalizados$V16)  # Ajusta `V16` al nombre de tu variable objetivo
# Probar un grid más amplio y más detallado
tune_grid <- expand.grid(
n.trees = seq(500, 1000, by = 100),         # Mayor número de árboles para un modelo más complejo
interaction.depth = seq(3, 8, by = 1),      # Mayor profundidad para captar relaciones complejas
shrinkage = c(0.01, 0.05, 0.1),             # Reducimos la tasa de aprendizaje para un ajuste más cuidadoso
n.minobsinnode = c(5, 10)                   # Variamos el tamaño mínimo de observaciones en los nodos terminales
)
# Ajustar el modelo con el nuevo grid
set.seed(1234)
modelo_gbm_tuned <- train(
V16 ~ .,
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = trainControl(method = "cv", number = 10),
tuneGrid = tune_grid
)
# Ver los resultados
modelo_gbm_tuned$results
predicciones <- predict(modelo_gbm_tuned, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(predicciones, credit.Datos.Test.Normalizados$V16)  # Ajusta `V16` al nombre de tu variable objetivo
summary(credit.Datos.Train.Normalizados)
prop.table(table(credit.Datos.Train.Normalizados$V16))
# Establecer un control de entrenamiento con validación cruzada de 10 pliegues
control <- trainControl(method = "cv", number = 10)
# Definir un grid de búsqueda más amplio para mejorar la precisión
tuneGrid <- expand.grid(
n.trees = seq(100, 1000, by = 100),              # Número de árboles
interaction.depth = seq(1, 5, by = 1),           # Profundidad del árbol
shrinkage = c(0.05, 0.1, 0.2, 0.3),              # Tasa de aprendizaje
n.minobsinnode = c(5, 10, 15)                    # Mínimo de observaciones en nodo final
)
# Entrenar el modelo gbm usando el grid de hiperparámetros
set.seed(123)
modelo_gbm <- train(
V16 ~ .,
data = credit.Datos.Train.Normalizados,
method = "gbm",
trControl = control,
tuneGrid = tuneGrid,
verbose = FALSE
)
# Ver los mejores hiperparámetros encontrados
print(modelo_gbm)
# Evaluar el modelo con el conjunto de prueba
pred <- predict(modelo_gbm, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(pred, credit.Datos.Test.Nornalizados$V16)
# Evaluar el modelo con el conjunto de prueba
pred <- predict(modelo_gbm, newdata = credit.Datos.Test.Normalizados)
confusionMatrix(pred, credit.Datos.Test.Normalizados$V16)
library(caret)
library(randomForest)
set.seed(1234)
# Definir el control de validación cruzada
control <- trainControl(method = "cv", number = 10)
# Definir el grid de hiperparámetros para explorar
tuneGrid <- expand.grid(
mtry = c(2, 3, 4, 5, 6),          # Ajusta según el número de variables en tu conjunto de datos
ntree = c(100, 500, 1000),        # Incrementa si quieres un ajuste más preciso a costa de tiempo de cómputo
nodesize = c(1, 5, 10)            # Tamaños de nodo mínimo
)
# Entrenar el modelo Random Forest con el grid de hiperparámetros
modelo_rf <- train(
V16 ~ .,                            # Sustituye V16 por el nombre de tu variable objetivo si es distinto
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneGrid = tuneGrid,
importance = TRUE                   # Para calcular la importancia de las variables
)
set.seed(1234)
# Definir el control de validación cruzada
control <- trainControl(method = "cv", number = 10)
# Ampliar el grid con valores mayores para `mtry`
tuneGrid <- expand.grid(
mtry = c(6, 7, 8, 9, 10, 11, 12)  # Valores mayores para `mtry`
)
# Ajustar el modelo Random Forest con valores más altos de ntree y nodesize
modelo_rf <- train(
V16 ~ .,                            # Cambia V16 si tu variable objetivo tiene otro nombre
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneGrid = tuneGrid,
ntree = 1000,                       # Incrementar el número de árboles
nodesize = 3                        # Probar con un tamaño de nodo menor
)
# Mostrar los mejores parámetros encontrados y resultados de precisión
print(modelo_rf$bestTune)
print(modelo_rf)
predicciones <- predict(modelo_rf, newdata = credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
set.seed(1234)
# Contar el número de variables predictoras en los datos
num_predictors <- ncol(credit.Datos.Train.Rf) - 1  # Restamos 1 porque la última columna es la variable objetivo
# Ajustar el rango de `mtry` a un valor válido
tuneGrid <- expand.grid(
mtry = seq(2, min(12, num_predictors))  # Elegimos de 2 a 12 o el máximo posible
)
# Definir el control de validación cruzada
control <- trainControl(method = "cv", number = 10)
# Ajustar el modelo Random Forest con valores de ntree y nodesize
modelo_rf <- train(
V16 ~ .,                            # Cambia V16 si tu variable objetivo tiene otro nombre
data = credit.Datos.Train.Rf,
method = "rf",
trControl = control,
tuneGrid = tuneGrid,
ntree = 1000,                       # Incrementar el número de árboles
nodesize = 3                        # Reducir el tamaño de nodo
)
# Mostrar los mejores parámetros encontrados y resultados de precisión
print(modelo_rf$bestTune)
print(modelo_rf)
predicciones <- predict(modelo_rf, newdata = credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
# Definir valores iniciales para los hiperparámetros
set.seed(1234)
max_accuracy <- 0.85
current_accuracy <- 0
attempt <- 1
# Bucle para ajustar los valores de hiperparámetros hasta alcanzar la precisión deseada
while (current_accuracy < max_accuracy) {
# Valores aleatorios para los hiperparámetros en cada iteración
mtry_val <- sample(2:12, 1)  # Selecciona un valor aleatorio de mtry entre 2 y 12
ntree_val <- sample(seq(500, 2000, by = 100), 1)  # Selecciona un valor aleatorio de ntree entre 500 y 2000
nodesize_val <- sample(1:5, 1)  # Selecciona un valor aleatorio de nodesize entre 1 y 5
# Ajuste del modelo con los hiperparámetros seleccionados
rf_model <- randomForest(
V16 ~ .,
data = credit.Datos.Train.Rf,
mtry = mtry_val,
ntree = ntree_val,
nodesize = nodesize_val
)
# Calcular la precisión usando la matriz de confusión en datos de entrenamiento
predictions <- predict(rf_model, credit.Datos.Train.Rf)
confusion <- confusionMatrix(predictions, credit.Datos.Train.Rf$V16)
current_accuracy <- confusion$overall["Accuracy"]
# Imprimir resultados de la iteración
cat("\nIntento:", attempt)
cat("\nmtry:", mtry_val, "ntree:", ntree_val, "nodesize:", nodesize_val)
cat("\nAccuracy:", current_accuracy, "\n")
# Incrementar el contador de intentos
attempt <- attempt + 1
}
# Mostrar los mejores hiperparámetros encontrados
cat("\nHiperparámetros óptimos encontrados:")
cat("\nmtry:", mtry_val, "ntree:", ntree_val, "nodesize:", nodesize_val)
cat("\nPrecisión final:", current_accuracy, "\n")
# Configurar los mejores hiperparámetros encontrados
best_mtry <- 11
best_ntree <- 1000
best_nodesize <- 5
# Entrenar el modelo con los hiperparámetros óptimos en el conjunto de entrenamiento
library(randomForest)
set.seed(1234)
rf_final_model <- randomForest(
V16 ~ .,
data = credit.Datos.Train.Rf,
mtry = best_mtry,
ntree = best_ntree,
nodesize = best_nodesize
)
# Predecir en el conjunto de prueba
predictions <- predict(rf_final_model, credit.Datos.Test)
# Crear una matriz de confusión para evaluar el rendimiento
confusion_matrix <- table(Predicted = predictions, Actual = credit.Datos.Test$V16)
# Calcular la precisión
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
# Mostrar los resultados
cat("\nMatriz de confusión:\n")
print(confusion_matrix)
cat("\nPrecisión en el conjunto de prueba:", accuracy, "\n")
# Definir valores iniciales para los hiperparámetros
set.seed(1234)
max_accuracy <- 0.85
current_accuracy <- 0
attempt <- 1
# Bucle para ajustar los valores de hiperparámetros hasta alcanzar la precisión deseada
while (current_accuracy < max_accuracy) {
# Valores aleatorios para los hiperparámetros en cada iteración
mtry_val <- sample(2:12, 1)  # Selecciona un valor aleatorio de mtry entre 2 y 12
ntree_val <- sample(seq(500, 2000, by = 100), 1)  # Selecciona un valor aleatorio de ntree entre 500 y 2000
nodesize_val <- sample(1:5, 1)  # Selecciona un valor aleatorio de nodesize entre 1 y 5
# Ajuste del modelo con los hiperparámetros seleccionados
rf_model <- randomForest(
V16 ~ .,
data = credit.Datos.Train.Rf,
mtry = mtry_val,
ntree = ntree_val,
nodesize = nodesize_val
)
# Calcular la precisión usando la matriz de confusión en datos de entrenamiento
predictions <- predict(rf_model, newdata=credit.Datos.Test.Rf)
confusion <- confusionMatrix(predictions, credit.Datos.Test.Rf$V16)
current_accuracy <- confusion$overall["Accuracy"]
# Imprimir resultados de la iteración
cat("\nIntento:", attempt)
cat("\nmtry:", mtry_val, "ntree:", ntree_val, "nodesize:", nodesize_val)
cat("\nAccuracy:", current_accuracy, "\n")
# Incrementar el contador de intentos
attempt <- attempt + 1
}
# Cargar los paquetes necesarios
library(caret)
library(randomForest)
# Configurar la semilla para reproducibilidad
set.seed(1234)
# Definir el control de entrenamiento con validación cruzada
control <- trainControl(
method = "cv",         # Usar validación cruzada
number = 10,           # Número de particiones (10-fold CV)
search = "grid"        # Realizar una búsqueda en malla
)
# Definir la malla de hiperparámetros para buscar
tune_grid <- expand.grid(
mtry = c(2, 4, 6, 8, 10, 12),      # Número de variables a considerar en cada split
ntree = c(500, 1000, 1500),        # Número de árboles en el bosque
nodesize = c(1, 5, 10)             # Número mínimo de observaciones en los nodos terminales
)
# Entrenar el modelo usando la búsqueda automática de hiperparámetros
modelo_rf <- train(
V16 ~ .,                                # Fórmula del modelo
data = credit.Datos.Train.Normalizados, # Conjunto de datos de entrenamiento
method = "rf",                          # Especificar Random Forest como método
trControl = control,                    # Control de entrenamiento con CV
tuneGrid = tune_grid                    # Malla de hiperparámetros
)
# Cargar los paquetes necesarios
library(caret)
library(randomForest)
# Configurar la semilla para reproducibilidad
set.seed(1234)
# Definir el control de entrenamiento con validación cruzada
control <- trainControl(
method = "cv",          # Usar validación cruzada
number = 10,            # Número de particiones (10-fold CV)
search = "grid"         # Realizar una búsqueda en malla
)
# Definir la malla de hiperparámetros solo para mtry
tune_grid <- expand.grid(
mtry = c(2, 4, 6, 8, 10, 12)       # Número de variables a considerar en cada split
)
# Entrenar el modelo usando la búsqueda de hiperparámetros solo con mtry
modelo_rf <- train(
V16 ~ .,                                # Fórmula del modelo
data = credit.Datos.Train.Normalizados, # Conjunto de datos de entrenamiento
method = "rf",                          # Especificar Random Forest como método
trControl = control,                    # Control de entrenamiento con CV
tuneGrid = tune_grid,                   # Malla de hiperparámetros solo para mtry
ntree = 1000                            # Número de árboles configurado directamente
)
# Mostrar los resultados del modelo
print(modelo_rf)
# Ver los hiperparámetros óptimos y precisión obtenida
cat("Mejores hiperparámetros:\n")
print(modelo_rf$bestTune)
cat("\nPrecisión obtenida con los mejores hiperparámetros:", max(modelo_rf$results$Accuracy), "\n")
# Ver la matriz de confusión en el conjunto de entrenamiento
predicciones <- predict(modelo_rf, credit.Datos.Train.Normalizados)
confusionMatrix(predicciones, credit.Datos.Train.Normalizados$V16)
# Cargar los paquetes necesarios
library(caret)
library(randomForest)
# Configurar la semilla para reproducibilidad
set.seed(1234)
# Definir el control de entrenamiento con validación cruzada
control <- trainControl(
method = "cv",          # Usar validación cruzada
number = 10,            # Número de particiones (10-fold CV)
search = "grid"         # Realizar una búsqueda en malla
)
# Definir la malla de hiperparámetros solo para mtry
tune_grid <- expand.grid(
mtry = c(2, 4, 6, 8, 10, 12)       # Número de variables a considerar en cada split
)
# Entrenar el modelo usando la búsqueda de hiperparámetros solo con mtry
modelo_rf <- train(
V16 ~ .,                                # Fórmula del modelo
data = credit.Datos.Train.Rf, # Conjunto de datos de entrenamiento
method = "rf",                          # Especificar Random Forest como método
trControl = control,                    # Control de entrenamiento con CV
tuneGrid = tune_grid,                   # Malla de hiperparámetros solo para mtry
ntree = 1000                            # Número de árboles configurado directamente
)
# Mostrar los resultados del modelo
print(modelo_rf)
# Ver los hiperparámetros óptimos y precisión obtenida
cat("Mejores hiperparámetros:\n")
print(modelo_rf$bestTune)
cat("\nPrecisión obtenida con los mejores hiperparámetros:", max(modelo_rf$results$Accuracy), "\n")
# Ver la matriz de confusión en el conjunto de entrenamiento
predicciones <- predict(modelo_rf, newdata=credit.Datos.Test.Rf)
confusionMatrix(predicciones, credit.Datos.Test.Rf$V16)
